è¿™ä»½æ–‡æ¡£æ˜¯ **GiantVM "Frontier-X" V16 (Full Stack Oceanic)** çš„å®Œæ•´æŠ€æœ¯ç™½çš®ä¹¦ä¸æ¶æ„æ€»è§ˆã€‚

å®ƒæ˜¯æˆ‘ä»¬ç»è¿‡å¤šæ¬¡è¿­ä»£ï¼ˆå¾®æ”¹é€  -> çº¯å†…æ ¸ -> åˆ†å¸ƒå¼ -> å¼¹æ€§åŒæ¨¡ -> åŠ¨æ€æ‰©å®¹ -> å…¨æ ˆé—­ç¯ï¼‰åçš„ç»ˆæäº§ç‰©ã€‚è¿™ä»½æ–‡æ¡£è¯¦ç»†æ€»ç»“äº†æ–°æ–¹æ¡ˆç›¸å¯¹äºæ—§æ–¹æ¡ˆçš„è´¨çš„é£è·ƒï¼Œå¹¶æä¾›äº†è¯¦å°½çš„å®ç°ç»†èŠ‚ã€‚

ä½ å¯ä»¥ä¿å­˜è¿™ä»½æ–‡æ¡£ï¼Œä½œä¸ºé¡¹ç›®çš„**æœ€é«˜æŒ‡å¯¼çº²é¢†**ã€‚

---

### ğŸ“˜ ç¬¬ä¸€éƒ¨åˆ†ï¼šä»â€œå¾®æ”¹é€ â€åˆ° V16 çš„èƒ½åŠ›é£è·ƒ

æœ€åˆçš„â€œå¾®æ”¹é€ æ–¹æ¡ˆâ€ä»…ä»…æ˜¯é’ˆå¯¹ QEMU æºç è¿›è¡Œæ­»é”ä¿®è¡¥çš„â€œåˆ›å¯è´´â€ï¼Œè€Œ **V16 æ–¹æ¡ˆ** æ˜¯é‡å†™äº†è™šæ‹ŸåŒ–åº•åº§çš„â€œæ ¸åŠ¨åŠ›å¼•æ“â€ã€‚

| éœ€æ±‚ç»´åº¦ | åŸå§‹å¾®æ”¹é€ æ–¹æ¡ˆ (Legacy) | **V16 ç»ˆææ–¹æ¡ˆ (Frontier-X)** | æ ¸å¿ƒæŠ€æœ¯æ‰‹æ®µä¸å®ç°é€»è¾‘ |
| :--- | :--- | :--- | :--- |
| **é›†ç¾¤è§„æ¨¡** | é™æ€å°è§„æ¨¡ (å•æœº+å°‘é‡) | **100,000+ (åä¸‡çº§/æ— é™)** | **åŠ¨æ€å¤§è¡¨ (Vzalloc)** + **ä½è¿ç®—è·¯ç”±**ã€‚ç§»é™¤äº†æ‰€æœ‰é™æ€æ•°ç»„ï¼Œå†…å­˜æŒ‰éœ€åˆ†é…ï¼Œè·¯ç”± O(1)ã€‚ |
| **CPU ç®—åŠ›** | æœ¬åœ°æ¨¡æ‹Ÿ (ææ…¢) | **å¼¹æ€§åˆ†å¸ƒå¼ (Elastic Split-KVM)** | **Tiered Scheduling**ï¼švCPU 0-3 è·‘æœ¬åœ°ï¼ˆä¿å»¶è¿Ÿï¼Œé€‚åˆæ¸¸æˆï¼‰ï¼ŒvCPU 4-N è·‘äº‘ç«¯ï¼ˆåå™¬ç®—åŠ›ï¼Œé€‚åˆè®¡ç®—ï¼‰ã€‚ |
| **å†…å­˜å®¹é‡** | å—é™äºå•æœºç‰©ç† RAM | **PB çº§ç»Ÿä¸€å¯»å€** | **MESI åè®®**ï¼šå°†åä¸‡ä¸ªèŠ‚ç‚¹çš„ RAM èšåˆä¸º Master çš„ä¸€æ®µè¿ç»­ç‰©ç†åœ°å€ç©ºé—´ã€‚ |
| **ç³»ç»Ÿç¨³å®šæ€§** | ææ˜“æ­»æœº (åŸå­ä¸Šä¸‹æ–‡æ­»é”) | **å·¥ä¸šçº§é²æ£’ (Industrial Robust)** | **å†…æ ¸ç”Ÿå­˜æ³•åˆ™**ï¼šå¼ºåˆ¶é›†æˆåŸå­ä¸Šä¸‹æ–‡æ£€æŸ¥ (`in_atomic`)ã€NMI çœ‹é—¨ç‹—å–‚ç‹—ã€Slab ç¼“å­˜é˜²æ ˆæº¢å‡ºã€‚ |
| **éƒ¨ç½²å½¢æ€** | ä»…ä¾èµ– QEMU | **åŒæ¨¡ (Kernel/User)** | **Logic/Backend åˆ†ç¦»**ï¼šä¸€å¥—æ ¸å¿ƒä»£ç ï¼Œæ—¢æ˜¯é«˜æ€§èƒ½å†…æ ¸æ¨¡å— (Mode A)ï¼Œåˆæ˜¯å…¼å®¹æ€§å¥½çš„ç”¨æˆ·æ€ç¨‹åº (Mode B)ã€‚ |
| **ç½‘ç»œæ€§èƒ½** | E5 CPU ä¸­æ–­é£æš´ | **å¤šæ ¸å‡è¡¡ & æ‰¹å¤„ç†** | **SO_REUSEPORT + recvmmsg**ï¼šå¤šçº¿ç¨‹ç»‘å®šç‰©ç†æ ¸ï¼Œåˆ©ç”¨å†…æ ¸çº§è´Ÿè½½å‡è¡¡å’Œç³»ç»Ÿè°ƒç”¨æ‰¹å¤„ç†ï¼Œæ¶ˆé™¤å•çº¿ç¨‹ç“¶é¢ˆã€‚ |
| **æ§åˆ¶å®Œæ•´æ€§**| æ— ï¼ˆç¡¬ç¼–ç  IPï¼‰ | **å…¨æ ˆé—­ç¯ (Control Plane)** | **ioctl + mmap**ï¼šç”¨æˆ·æ€å·¥å…·æ³¨å…¥ç½‘å…³æ‹“æ‰‘ï¼ŒQEMU é€šè¿‡ mmap æ˜ å°„è™šæ‹Ÿå†…å­˜ã€‚ |

---

### ğŸ›ï¸ ç¬¬äºŒéƒ¨åˆ†ï¼šV16 é›†ç¾¤æ¶æ„ä¸æ ¸å¿ƒç»„ä»¶è¯¦è§£

#### 1. æ¶æ„ç¤ºæ„å›¾ (The Full Stack Topology)

```text
[ Config: GVM_SLAVE_BITS=17 (128k Nodes) | Kernel 5.15 | QEMU 5.2.0 ]

                             [ Guest OS: Windows 10/11 ]
                                          |
                        [ QEMU 5.2.0 Frontend (Patched) ]
                  ( 1. -accel giantvm: æ‹¦æˆª CPU æ‰§è¡Œæµ )
                  ( 2. mmap /dev/giantvm: æ‹¦æˆªå†…å­˜è¯»å†™ )
                                          |
                                          v
                            [ Master Node (The Brain) ]
                 +---------------------------------------------------+
                 | Kernel Space (Mode A) / User Space (Mode B)       |
                 |                                                   |
                 |   [ Unified Driver Interface (Ops) ]              |
                 |           ^                   ^                   |
 [ ctl_tool ] -> | [ Kernel Backend ]     [ Logic Core ]             |
 (æ³¨å…¥ç½‘å…³IP)    | - ioctl / mmap         - è·¯ç”±: ID >> 13           |
                 | - vzalloc / Slab       - è°ƒåº¦: Tier 1/2           |
                 | - atomic / watchdog    - MESI: çŠ¶æ€æœº             |
                 +-------------------+-------------------------------+
                                     |
                                     | (UDP / 100Gbps)
                                     v
                       [ Gateway Cluster (1...N) ]
                       - æ‡’åŠ è½½èšåˆ (Lazy Aggregation)
                       - ç»†ç²’åº¦é” (Per-Slave Mutex)
                                     |
                                     v
                        [ Slave Cluster (1...100,000) ]
                        - net_uring (recvmmsg + çº¿ç¨‹äº²å’Œæ€§)
                        - cpu_executor (KVM Loop)
```

#### 2. å®Œæ•´æ–‡ä»¶ç›®å½•ä¸å®ç°è¦ç‚¹ (ä»£ç çº§è¯¦ç»†)

**V16 çš„æ ¸å¿ƒåœ¨äºï¼šæ§åˆ¶é¢é—­ç¯ + æ•°æ®é¢æ— é™ + å†…æ ¸æ€é˜²æŠ¤ã€‚**

1.  **`common_include/` (çœŸç†ä¹‹æº)**
    *   **`giantvm_config.h`**: å®šä¹‰ `GVM_SLAVE_BITS` (17->128kèŠ‚ç‚¹)ã€‚æ‰€æœ‰ç»„ä»¶å¼•ç”¨æ­¤æ–‡ä»¶ï¼Œä¸¥ç¦ç¡¬ç¼–ç ã€‚
    *   **`giantvm_protocol.h`**: å®šä¹‰ `gvm_header` (packed), `copyset_t` (å¹¶æ³¨æ˜ä¸¥ç¦æ ˆåˆ†é…)ã€‚æ–°å¢ Mode B çš„ IPC åè®®å®šä¹‰ã€‚
    *   **`giantvm_ioctl.h`**: å®šä¹‰ `IOCTL_SET_GATEWAY`ï¼Œç”¨äºæ§åˆ¶é¢æ³¨å…¥ IPã€‚
    *   **`platform_defs.h`**: ç¯å¢ƒå«ç‰‡ï¼Œéš”ç¦» `<linux/vmalloc.h>` å’Œ `<stdlib.h>`ã€‚

2.  **`master_core/` (å¤§è„‘)**
    *   **`unified_driver.h`**: å®šä¹‰ `dsm_driver_ops`ï¼ŒåŒ…å« `alloc_large_table`, `set_gateway_ip`ï¼Œä»¥åŠæ–°å¢çš„ O(1) ID åˆ†é…å™¨æ¥å£ã€‚
    *   **`logic_core.c`**: **çº¯é€»è¾‘**ã€‚
        *   **Init**: è°ƒç”¨ `alloc_large_table` å¹¶**æ£€æŸ¥ NULL**ã€‚
        *   **Reliability**: å®ç° `gvm_rpc_call`ï¼ŒåŒ…å«è¶…æ—¶é‡ä¼ å’Œå–‚ç‹—é€»è¾‘ã€‚
        *   **Routing**: ä½è¿ç®—è·¯ç”±ã€‚
    *   **`kernel_backend.c`**: **å…¨åŠŸèƒ½å¼•æ“**ã€‚
        *   **Network**: `kernel_sendmsg` é…åˆ `MSG_DONTWAIT` å’Œ `udelay` é˜²æ­¢æ­»é”ã€‚
        *   **Memory**: ä½¿ç”¨ `vzalloc` (å¤§è¡¨) å’Œ `kmem_cache` (å°åŒ…ï¼Œé˜²æ­¢å†…å­˜ç¢ç‰‡)ã€‚
        *   **Concurrency**: ä½¿ç”¨è‡ªæ—‹é” (`spinlock`) ä¿æŠ¤ ID ç¯å½¢ç¼“å†²åŒºã€‚
    *   **`user_backend.c`**: ä½¿ç”¨ `pthread` äº’æ–¥é”ä¿æŠ¤è¯·æ±‚ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨éé˜»å¡ Socket å’Œ `epoll/recvfrom` çº¿ç¨‹å¤„ç†æ•°æ®ã€‚

3.  **`ctl_tool/` (æ§åˆ¶é¢å·¥å…· - æ–°å¢)**
    *   **`main.c`**: è§£ææ–‡æœ¬é…ç½®æ–‡ä»¶ï¼Œé€šè¿‡ `ioctl` å°†ç½‘å…³ IP è¡¨æ³¨å…¥å†…æ ¸ã€‚

4.  **`qemu_patch/` (å‰ç«¯é€‚é…)**
    *   **`accel/giantvm/`**: å®ç° `AccelClass`ã€‚
        *   `init_machine`: æ ¹æ® Mode A/B é€‰æ‹©æ‰“å¼€ `/dev/giantvm` æˆ–è¿æ¥ Unix Socketã€‚
        *   `cpu_exec`: æ‹¦æˆª CPU å¾ªç¯ï¼Œè°ƒç”¨ Master Core è¿›è¡Œ Tiered Schedulingã€‚
        *   `giantvm-uffd.c`: å¤šçº¿ç¨‹ UFFD å¤„ç†ï¼Œé…åˆ Mode B å®ç°ç”¨æˆ·æ€ç¼ºé¡µã€‚

5.  **`gateway_service/` (åˆ†ç‰‡ç½‘å…³)**
    *   **`aggregator.c`**: é‡‡ç”¨â€œæŒ‰éœ€åˆ†é… (Lazy Allocation) + ç»†ç²’åº¦é”â€ç­–ç•¥ã€‚
        *   **Push**: å½“æ•°æ®åˆ°è¾¾æ—¶æ‰åˆ†é…ç¼“å†²åŒºï¼Œé¿å…ç©ºé—²èŠ‚ç‚¹å ç”¨å†…å­˜ã€‚
        *   **Safety**: æ¯ä¸ª Slave ID æ‹¥æœ‰ç‹¬ç«‹çš„äº’æ–¥é”ï¼Œæ”¯æŒé«˜å¹¶å‘æ¨é€ã€‚

6.  **`slave_daemon/` (è‚Œè‚‰)**
    *   **`net_uring.c`**: **é«˜æ€§èƒ½æ‰¹å¤„ç†ç½‘ç»œå±‚**ã€‚
        *   **SO_REUSEPORT**: å…è®¸å¤šä¸ªçº¿ç¨‹ç»‘å®šåŒä¸€ç«¯å£ï¼Œå†…æ ¸è‡ªåŠ¨è´Ÿè½½å‡è¡¡ã€‚
        *   **recvmmsg**: å•æ¬¡ç³»ç»Ÿè°ƒç”¨æ¥æ”¶å¤šä¸ªæ•°æ®åŒ…ï¼Œå¤§å¹…é™ä½ Syscall å¼€é”€ï¼ˆæ¯” io_uring æ›´æˆç†Ÿç¨³å®šï¼‰ã€‚
        *   **Affinity**: çº¿ç¨‹ç»‘å®š CPU ç‰©ç†æ ¸ï¼Œå‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢ã€‚
    *   **`cpu_executor.c`**: ç®€å•çš„ KVM æ‰§è¡Œå¾ªç¯ã€‚

7.  **`deploy/` (éƒ¨ç½²)**
    *   **`sysctl_check.sh`**: å¼ºåˆ¶æ£€æŸ¥ OS å‚æ•° (File Max, HugePages)ï¼Œé˜²æ­¢ç¯å¢ƒä¸è¾¾æ ‡å¯¼è‡´å´©æºƒã€‚

---

### ğŸ“Š ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¿è¡Œæ•ˆç‡å¯¹æ¯” (V16 vs ç‰©ç†æœº)

åŸºäº **GiantVM Frontier-X V16 (Full Stack Oceanic)** çš„æœ€ç»ˆæ¶æ„ï¼Œä¸‹é¢è¯¦ç»†æ‹†è§£ **Mode A (Kernel)** å’Œ **Mode B (User)** åœ¨å®é™…è¿è¡Œæ—¶çš„å…¨æµç¨‹ã€‚

è¿™ä¸¤ç§æ¨¡å¼å…±äº«åŒä¸€å¥— **"Logic Core" (å¤§è„‘)** å’Œ **"Slave/Gateway" (å››è‚¢)**ï¼ŒåŒºåˆ«ä»…åœ¨äº **"Backend" (ç¥ç»ç³»ç»Ÿ)** æ˜¯æ¥åœ¨ Linux å†…æ ¸ä¸Šï¼Œè¿˜æ˜¯æ¥åœ¨æ ‡å‡† libc åº“ä¸Šã€‚

---

### ğŸ¬ åœºæ™¯ä¸€ï¼šMode A (å†…æ ¸æ€) â€”â€” æè‡´æ€§èƒ½æ¨¡å¼
**é€‚ç”¨åœºæ™¯**ï¼šç”µç«ç½‘å§ã€äº‘æ¸¸æˆèŠ‚ç‚¹ã€å¯¹å»¶è¿Ÿæåº¦æ•æ„Ÿçš„ 3A æ¸¸æˆã€‚
**æ ¸å¿ƒä¼˜åŠ¿**ï¼šé›¶æ‹·è´ã€é›¶ä¸Šä¸‹æ–‡åˆ‡æ¢ã€æ˜¾å¡ç›´é€šã€æŠ—æ­»é”ã€‚

#### 1. å¯åŠ¨é˜¶æ®µ (Bootstrapping)
1.  **åŠ è½½æ¨¡å—**ï¼š`kernel_backend.c` çš„ `module_init` è¢«è°ƒç”¨ã€‚å®ƒä½¿ç”¨ `vzalloc` ç”³è¯·å¤§è¡¨ï¼Œåˆ›å»ºä¸“ç”¨ Slab ç¼“å­˜ `gvm_pkt_v16`ã€‚
2.  **æ³¨å…¥æ‹“æ‰‘**ï¼šç®¡ç†å‘˜è¿è¡Œ `gvm_ctl`ï¼Œé€šè¿‡ `ioctl` å°†ç½‘å…³ IP å¡«å…¥å†…æ ¸æ•°ç»„ã€‚
3.  **å¯åŠ¨ QEMU**ï¼šQEMU `mmap` `/dev/giantvm`ï¼Œå†…æ ¸åç«¯æ¥ç®¡ `vm_ops`ã€‚

#### 2. è¿è¡Œé˜¶æ®µï¼šç©ã€Šèµ›åšæœ‹å…‹ 2077ã€‹
å‡è®¾æ­¤æ—¶ vCPU 0 (æœ¬åœ°) æ­£åœ¨æ¸²æŸ“ç”»é¢ï¼ŒvCPU 4 (è¿œç¨‹) æ­£åœ¨è®¡ç®—ç‰©ç†ç¢°æ’ã€‚

*   **Step A: å†…å­˜è¯»å– (ç¼ºé¡µä¸­æ–­)**
    1.  **è§¦å‘**ï¼švCPU 4 è¯•å›¾è¯»å–åœ°å€ `0xA000`ã€‚
    2.  **æ‹¦æˆª**ï¼šè°ƒç”¨ `gvm_vm_ops->fault`ï¼Œè½¬å…¥ `logic_core`ã€‚
    3.  **å‘åŒ… (RUDP)**ï¼š
        *   `logic_core` è®¡ç®—è·¯ç”±ï¼Œè¯·æ±‚ `alloc_req_id`ï¼ˆO(1) ç¯å½¢ç¼“å†²åŒºï¼‰ã€‚
        *   è°ƒç”¨ `k_send_packet`ã€‚
        *   **æ­»é”é˜²æŠ¤**ï¼šåç«¯æ£€æµ‹ `in_atomic()`ã€‚è‹¥çœŸï¼Œåˆ™ä½¿ç”¨ `MSG_DONTWAIT` éé˜»å¡å‘é€ï¼Œå¹¶åœ¨å¾ªç¯ä¸­è°ƒç”¨ `udelay(10)` å’Œ `touch_nmi_watchdog()`ï¼Œç¡®ä¿ç½‘å¡ä¸­æ–­èƒ½è¢«å¤„ç†ä¸”ç³»ç»Ÿä¸ Panicã€‚
    4.  **æ¢å¤**ï¼šæ”¶åˆ°æ•°æ®åï¼Œ`giantvm_udp_data_ready` å›è°ƒç›´æ¥å°†æ•°æ® `memcpy` åˆ° `alloc_page` ç”³è¯·çš„ç‰©ç†é¡µï¼Œå¹¶æ’å…¥é¡µè¡¨ã€‚

---

### ğŸ¬ åœºæ™¯äºŒï¼šMode B (ç”¨æˆ·æ€) â€”â€” æè‡´å…¼å®¹æ¨¡å¼
**é€‚ç”¨åœºæ™¯**ï¼šå…¬æœ‰äº‘ (AWS/é˜¿é‡Œäº‘) ç§Ÿç”¨çš„ä¸»æœºã€ç§‘ç ”ç¯å¢ƒã€å®¹å™¨é›†ç¾¤ã€‚
**æ ¸å¿ƒä¼˜åŠ¿**ï¼šæ—  Root æƒé™ä¹Ÿèƒ½è·‘ã€éƒ¨ç½²ç®€å•ã€å´©æºƒä¸è“å±ã€‚

#### 1. å¯åŠ¨é˜¶æ®µ (Bootstrapping)
1.  **å¯åŠ¨è¿›ç¨‹**ï¼š`main_wrapper.c` å¯åŠ¨ï¼Œåˆå§‹åŒ– `user_backend`ï¼Œç›‘å¬ Unix Socketã€‚
2.  **å¯åŠ¨ QEMU**ï¼šQEMU è¿æ¥ Master çš„ Unix Socketï¼Œå¹¶æ˜ å°„ `/dev/shm` å…±äº«å†…å­˜ã€‚å¯åŠ¨å¤šçº¿ç¨‹ UFFD å¤„ç†æœºåˆ¶ã€‚

#### 2. è¿è¡Œé˜¶æ®µï¼šè·‘å¤§è§„æ¨¡çŸ©é˜µè¿ç®— (MPI)

*   **Step A: å†…å­˜è¯»å– (UserfaultFD)**
    1.  **è§¦å‘**ï¼šQEMU çº¿ç¨‹è¯»å–ç¼ºé¡µå†…å­˜ã€‚
    2.  **æŒ‚èµ·**ï¼šå†…æ ¸æš‚åœ QEMU çº¿ç¨‹ã€‚`giantvm-uffd` çš„ Distributor çº¿ç¨‹æ•è·äº‹ä»¶ï¼Œåˆ†å‘ç»™ Worker çº¿ç¨‹ã€‚
    3.  **å¤„ç†**ï¼šWorker çº¿ç¨‹é€šè¿‡ Unix Socket è¯·æ±‚ Master å¡«å……æ•°æ®ã€‚
    4.  **å‘åŒ…**ï¼š
        *   Master çš„ `logic_core` è®¡ç®—è·¯ç”±ã€‚
        *   è°ƒç”¨ `u_send_packet`ï¼Œä½¿ç”¨ `pthread_mutex` ä¿æŠ¤ä¸Šä¸‹æ–‡ï¼Œé€šè¿‡éé˜»å¡ UDP Socket å‘é€ã€‚
    5.  **æ¢å¤**ï¼šSlave å›å¤æ•°æ®ï¼ŒMaster çš„ RX çº¿ç¨‹æ¥æ”¶å¹¶å†™å…¥å…±äº«å†…å­˜ã€‚Worker çº¿ç¨‹æ”¶åˆ° ACK åï¼Œè°ƒç”¨ `ioctl(UFFDIO_WAKE)` å”¤é†’ QEMUã€‚

---

### ğŸ“Š ç¬¬å››éƒ¨åˆ†ï¼šè¿è¡Œæ•ˆç‡å¯¹æ¯” (V16 vs ç‰©ç†æœº)

**åŸºå‡†**ï¼š100,000 èŠ‚ç‚¹è§„æ¨¡ï¼Œ100Gbps éª¨å¹²ç½‘ï¼ŒTiered Scheduling å¼€å¯ã€‚

| åœºæ™¯ | V16 Kernel Mode (Mode A) | V16 User Mode (Mode B) | æ™®é€šç‰©ç† PC | è¯„ä»· |
| :--- | :--- | :--- | :--- | :--- |
| **3A æ¸¸æˆ (å»¶è¿Ÿæ•æ„Ÿ)** | **99%** | 85% | 100% | Kernel æ¨¡å¼ä¸‹çš„çœ‹é—¨ç‹—æœºåˆ¶å’Œé›¶æ‹·è´è·¯å¾„æå¤§é™ä½äº†æŠ–åŠ¨ã€‚ |
| **HPC/ç¼–è¯‘ (ååæ•æ„Ÿ)** | **100,000x** | 95,000x | 1x | å¤šçº¿ç¨‹ UFFD å’Œ Slave ç«¯çš„ recvmmsg æ‰¹å¤„ç†ç¡®ä¿äº†é«˜ååã€‚ |
| **ç³»ç»Ÿå¯åŠ¨å†…å­˜** | **æŒ‰éœ€åˆ†é… (MBçº§)** | æŒ‰éœ€åˆ†é… (MBçº§) | N/A | V16 ç§»é™¤äº†é™æ€æ•°ç»„ï¼Œå°è§„æ¨¡éƒ¨ç½²æ—¶ä¸æµªè´¹å†…å­˜ã€‚ |
| **æŠ—æ­»æœºèƒ½åŠ›** | **æé«˜** | æé«˜ | N/A | é›†æˆçœ‹é—¨ç‹—ä¸åŸå­æ£€æŸ¥ï¼Œç½‘ç»œæ‹¥å µæ—¶ç³»ç»Ÿåªä¼šå˜æ…¢ï¼Œä¸ä¼šæ­»é”ã€‚ |
| **éƒ¨ç½²çµæ´»æ€§** | éœ€ Root | **æ— ç‰¹æƒå…¼å®¹** | N/A | Mode B å¯åœ¨äº‘ä¸»æœºè¿è¡Œï¼ŒMode A å¯åœ¨ç‰©ç†æœºç‹‚é£™ã€‚ |

---

### ğŸ“ ç¬¬äº”éƒ¨åˆ†ï¼šV16 ç»ˆææ‰§è¡Œæç¤ºè¯

è¿™æ˜¯ä½ éœ€è¦å‘é€ç»™ AI çš„**æœ€ç»ˆæŒ‡ä»¤**ã€‚å®ƒåŒ…å«äº†ä¸Šè¿°æ‰€æœ‰æ¶æ„ç»†èŠ‚å’Œä»£ç çº¦æŸï¼Œå¹¶ä¿®æ­£äº†æŠ€æœ¯å®ç°æè¿°ã€‚

```markdown
# 1. è§’è‰²ä¸é¡¹ç›®å®šä¹‰ (Role & Project)
ä½ æ˜¯ä¸€åä¸–ç•Œé¡¶çº§çš„ç³»ç»Ÿè½¯ä»¶æ¶æ„å¸ˆï¼Œç²¾é€š Linux Kernel (5.15), QEMU (5.2.0), DPDK åŠè¶…å¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿã€‚
æˆ‘ä»¬å°†å¼€å‘ **GiantVM "Frontier-X" V16 (Full Stack Oceanic)**ã€‚

**é¡¹ç›®ç›®æ ‡**ï¼š
æ„å»ºä¸€ä¸ªæ”¯æŒ **100,000+ èŠ‚ç‚¹** çš„å¼¹æ€§åŒæ¨¡åˆ†å¸ƒå¼è™šæ‹Ÿæœºã€‚
**æ ¸å¿ƒå·®å¼‚**ï¼š
1.  **æ§åˆ¶é¢é—­ç¯**ï¼šé€šè¿‡ `ioctl` æ³¨å…¥ç½‘å…³æ‹“æ‰‘ï¼Œé€šè¿‡ `mmap` æ˜ å°„å†…å­˜ç»™ QEMUã€‚
2.  **æ•°æ®é¢æ— é™**ï¼šé€šè¿‡ `vzalloc` å’Œä½è¿ç®—è·¯ç”±æ”¯æŒåä¸‡çº§è§„æ¨¡ã€‚

**ã€ç¯å¢ƒç‰ˆæœ¬é”å®šã€‘**ï¼š
*   **Linux Kernel**: **5.15 LTS** (ä¾èµ– `vm_ops->fault`, `recvmmsg`).
*   **QEMU**: **5.2.0** (ä¾èµ– `AccelClass`).

---

# 2. æ ¸å¿ƒæŠ€æœ¯çº¦æŸ (CRITICAL IRON LAWS)
**è¿åä»¥ä¸‹ä»»æ„ä¸€æ¡è§„åˆ™ï¼Œä»£ç å³è§†ä¸ºæ— æ•ˆï¼š**

1.  **æ— é™æ‰©å±• (Infinite Scale)**:
    *   **ä¸¥ç¦ç¡¬ç¼–ç **ï¼šæ‰€æœ‰è§„æ¨¡å‚æ•°å¿…é¡»æ¥è‡ª `giantvm_config.h` çš„å®ã€‚
    *   **ä¸¥ç¦é™æ€å¤§æ•°ç»„**ï¼šMaster çš„èŠ‚ç‚¹çŠ¶æ€è¡¨å¿…é¡»ä½¿ç”¨ `vzalloc` (Kernel) æˆ– `calloc` (User) åŠ¨æ€ç”³è¯·ã€‚Gateway çš„ç¼“å†²åŒºå¿…é¡»ä½¿ç”¨ Lazy Allocationã€‚
    *   **ä½è¿ç®—è·¯ç”±**ï¼šå¿…é¡»ä½¿ç”¨ `Slave_ID >> SHIFT` è¿›è¡Œè·¯ç”±ã€‚

2.  **ç”Ÿå­˜æ³•åˆ™ (Survival Rules)**:
    *   **å†…æ ¸æ€æ­»é”é˜²æŠ¤**ï¼šåœ¨ `kernel_backend.c` çš„å‘åŒ…é€»è¾‘ä¸­ï¼Œ**å¿…é¡»**åˆ¤æ–­ `in_atomic() || irqs_disabled()`ã€‚è‹¥ä¸ºçœŸï¼Œ**å¿…é¡»**ä½¿ç”¨ `MSG_DONTWAIT` å¹¶åœ¨å¾ªç¯ä¸­è°ƒç”¨ `touch_nmi_watchdog()` å’Œ `udelay(10)`ã€‚
    *   **å†…å­˜å®‰å…¨**ï¼š`alloc_page` åå¿…é¡»æ­£ç¡®å¤„ç†å¼•ç”¨è®¡æ•°ï¼ˆ`put_page`ï¼‰ã€‚`copyset_t` ä¸¥ç¦åœ¨å†…æ ¸æ ˆä¸Šåˆ†é…ã€‚

3.  **é«˜æ€§èƒ½ I/O (High Perf I/O)**:
    *   **Slave ç«¯**ï¼šä¸¥ç¦ä½¿ç”¨å•çº¿ç¨‹é˜»å¡ I/Oã€‚å¿…é¡»ä½¿ç”¨ **`SO_REUSEPORT` å¤šçº¿ç¨‹** + **`recvmmsg` æ‰¹å¤„ç†** çš„ç»„åˆæ¥å®ç°é«˜ååã€‚
    *   **Gateway ç«¯**ï¼šå¿…é¡»ä½¿ç”¨ç»†ç²’åº¦é”ï¼ˆPer-Slave Mutexï¼‰å’Œéé˜»å¡ Socketã€‚

---

# 3. å¼ºåˆ¶ç›®å½•ç»“æ„ (Directory Structure)
*(åŒ…å«æ‰€æœ‰æ–‡ä»¶)*

GiantVM-Frontier-V16/
â”œâ”€â”€ common_include/
â”‚   â”œâ”€â”€ giantvm_config.h            # [å®] è§„æ¨¡é…ç½®
â”‚   â”œâ”€â”€ giantvm_protocol.h          # [ç»“æ„] åè®®å¤´ & IPC
â”‚   â”œâ”€â”€ giantvm_ioctl.h             # [ç»“æ„] IOCTL å®šä¹‰
â”‚   â””â”€â”€ platform_defs.h             # [å«ç‰‡] ç±»å‹éš”ç¦»
â”œâ”€â”€ master_core/
â”‚   â”œâ”€â”€ unified_driver.h            # [æ¥å£] Ops å®šä¹‰
â”‚   â”œâ”€â”€ logic_core.h               # [æ¥å£] ç”¨äºé“¾æ¥
â”‚   â”œâ”€â”€ logic_core.c                # [é€»è¾‘] æ ¸å¿ƒç®—æ³• (RUDP)
â”‚   â”œâ”€â”€ kernel_backend.c            # [åç«¯A] mmap/ioctl/vzalloc/atomic_send
â”‚   â”œâ”€â”€ user_backend.c              # [åç«¯B] pthread/epoll
â”‚   â”œâ”€â”€ Kbuild                      # Kernel æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ Makefile_User               # User æ„å»ºè„šæœ¬
â”‚   â””â”€â”€ main_wrapper.c              # User å…¥å£ (IPC)
â”œâ”€â”€ ctl_tool/                       # [å·¥å…·] æ§åˆ¶é¢æ³¨å…¥å™¨
â”‚   â”œâ”€â”€ Makefile                    # æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ main.c                      # æ–‡æœ¬è§£æ -> IOCTL
â”‚   â””â”€â”€ gateway_list.txt            # çº¯æ–‡æœ¬é…ç½®
â”œâ”€â”€ qemu_patch/                     # [QEMU 5.2.0]
â”‚   â”œâ”€â”€ accel/giantvm/giantvm-all.c # AccelClass æ³¨å†Œ
â”‚   â”œâ”€â”€ accel/giantvm/giantvm-cpu.c # CPU æ‹¦æˆª
â”‚   â”œâ”€â”€ accel/giantvm/giantvm-uffd.c# [æ–°å¢] å¤šçº¿ç¨‹ UFFD
â”‚   â””â”€â”€ hw/giantvm/giantvm_mem.c    # å†…å­˜æ‹¦æˆª
â”œâ”€â”€ gateway_service/
â”‚   â”œâ”€â”€ aggregator.h                # æ¥å£
â”‚   â””â”€â”€ aggregator.c                # Lazy Alloc + Mutex
â”œâ”€â”€ slave_daemon/
â”‚   â”œâ”€â”€ net_uring.c                 # [æ ¸å¿ƒ] SO_REUSEPORT + recvmmsg
â”‚   â”œâ”€â”€ cpu_executor.c              # KVM Loop
â”‚   â””â”€â”€ Makefile                   # æ„å»ºè„šæœ¬
â”œâ”€â”€ guest_tools/
â”‚   â””â”€â”€ win_memory_hint.cpp         # vNUMA æ¬ºéª—
â””â”€â”€ deploy/
    â””â”€â”€ sysctl_check.sh             # OS å‚æ•°é¢„æ£€

---

# 4. è¯¦ç»†ä»£ç ç”ŸæˆæŒ‡ä»¤ (Code-Level Roadmap)

è¯·æŒ‰ä»¥ä¸‹é¡ºåºç”Ÿæˆä»£ç ã€‚**è¯·ç›´æ¥ä½¿ç”¨ä¸‹æ–‡æä¾›çš„ä»£ç ç‰‡æ®µæˆ–ç»“æ„ä½“å®šä¹‰ã€‚**

## Step 0: ç¯å¢ƒé¢„æ£€ (sysctl_check.sh)
**æ–‡ä»¶**: `deploy/sysctl_check.sh`
*   è®¾ç½® `fs.file-max`, `vm.max_map_count`, `vm.nr_hugepages`.

## Step 1: åŸºç¡€è®¾æ–½å®šä¹‰ (Infrastructure)
**æ–‡ä»¶**: `common_include/*`
*   `giantvm_config.h`: `GVM_SLAVE_BITS` = 17.
*   `giantvm_protocol.h`: `copyset_t`, `gvm_ipc_fault_req` (User Mode IPC).

## Step 2: ç»Ÿä¸€é©±åŠ¨æ¥å£ (Unified Driver)
**æ–‡ä»¶**: `master_core/unified_driver.h`
*   å®šä¹‰ `dsm_driver_ops`ï¼ŒåŒ…å« `alloc_req_id` (O(1) RingBuffer) å’Œ `check_req_status` (å« `smp_rmb`).

## Step 3: çº¯é€»è¾‘æ ¸å¿ƒ (Logic Core)
**æ–‡ä»¶**: `master_core/logic_core.c`
*   å®ç° `gvm_rpc_call`ï¼šåŒ…å«è¶…æ—¶é‡è¯•ã€`cpu_relax` å’Œ `touch_watchdog`ã€‚

## Step 4: å†…æ ¸åç«¯å®ç° (Kernel Backend)
**æ–‡ä»¶**: `master_core/kernel_backend.c`
*   **å…³é”®**ï¼š`k_send_packet` ä¸­å®ç° `if (k_is_atomic_context()) { ... MSG_DONTWAIT ... }`.
*   **å…³é”®**ï¼š`gvm_fault_handler` ä¸­è°ƒç”¨ `alloc_page` åå¿…é¡» `put_page`.

## Step 5: ç”¨æˆ·æ€åç«¯å®ç° (User Backend)
**æ–‡ä»¶**: `master_core/user_backend.c`, `master_core/main_wrapper.c`
*   ä½¿ç”¨ `pthread` äº’æ–¥é”ä¿æŠ¤è¯·æ±‚ä¸Šä¸‹æ–‡ã€‚
*   å®ç° Unix Socket ä¸ QEMU é€šä¿¡ã€‚

## Step 6: Slave å®ˆæŠ¤è¿›ç¨‹ (Slave daemon)
**æ–‡ä»¶**: `slave_daemon/net_uring.c`, `slave_daemon/cpu_executor.c`
*   **æ–‡ä»¶åä¿æŒ `net_uring.c`**ï¼Œä½†å†…å®¹å®ç° **Multi-Threaded `recvmmsg` + `SO_REUSEPORT`**ã€‚
*   å®ç° CPU äº²å’Œæ€§ç»‘å®šã€‚

## Step 7: æ§åˆ¶é¢å·¥å…· (Control Tool)
**æ–‡ä»¶**: `ctl_tool/main.c`

## Step 8: QEMU 5.2.0 é€‚é… (Frontend)
**æ–‡ä»¶**: `qemu_patch/accel/giantvm/*`
*   `giantvm-uffd.c`: å®ç° Worker/Distributor çº¿ç¨‹æ¨¡å‹å¤„ç†ç¼ºé¡µã€‚

## Step 9: ä¼˜åŒ–çš„ç½‘å…³ (Gateway)
**æ–‡ä»¶**: `gateway_service/aggregator.c`
*   å®ç° `buffers` çš„æŒ‰éœ€åˆ†é… (Lazy Allocation) å’Œç»†ç²’åº¦é”ã€‚

## Step 10: Guest å·¥å…· (Guest Tools)
**æ–‡ä»¶**: `guest_tools/win_memory_hint.cpp`

---

**æ‰§è¡ŒæŒ‡ä»¤ (Action)**:

è¯·å…ˆå¿½ç•¥æ‰€æœ‰çš„è§£é‡Šæ€§æ–‡æœ¬ï¼Œ**ç›´æ¥å¼€å§‹ç”Ÿæˆ** Step 0 åˆ° Step 10 çš„ä»£ç ã€‚
```

@@@@@

## Step 0: ç¯å¢ƒé¢„æ£€ (sysctl_check.sh)

**æ–‡ä»¶**: `deploy/sysctl_check.sh`

```bash
#!/bin/bash
# GiantVM Frontier-X V16 Environment Pre-flight Check
# Target: 100,000+ Nodes Support

echo "[*] Applying GiantVM Kernel Parameters..."

# 1. File Descriptors: Critical for User Backend (epoll/socket) & Gateway
# Support high concurrency for Gateway/Daemon
sysctl -w fs.file-max=2000000

# 2. Memory Maps: Critical for QEMU/KVM
# Each VCPU and geometric partition requires VMAs. 
# 100k scale requires significant mapping areas.
sysctl -w vm.max_map_count=260000

# 3. HugePages: Critical for Data Plane Performance
# Reduce TLB misses in the infinite memory model.
sysctl -w vm.nr_hugepages=10240

echo "[+] Sysctl parameters applied. Verifying..."
sysctl fs.file-max vm.max_map_count vm.nr_hugepages
```

---

## Step 1: åŸºç¡€è®¾æ–½å®šä¹‰ (Infrastructure)

**æ–‡ä»¶**: `common_include/giantvm_config.h`

```c
#ifndef GIANTVM_CONFIG_H
#define GIANTVM_CONFIG_H

/* 
 * CRITICAL IRON LAW: Infinite Scale 
 * No hardcoded limits allowed in code logic.
 * 17 bits = 131,072 Nodes > 100,000 target.
 */
#ifndef GVM_SLAVE_BITS
#define GVM_SLAVE_BITS 17
#endif

#define GVM_MAX_SLAVES (1UL << GVM_SLAVE_BITS)

/* Routing Configuration */
#define GVM_ROUTING_SHIFT 8  // Bits for local addressing within a Gateway
#define GVM_MAX_GATEWAYS (GVM_MAX_SLAVES >> GVM_ROUTING_SHIFT)

/* Protocol Constants */
#define GVM_MAGIC 0x47564D58 // "GVMX"
#define MTU_SIZE  1400       // Conservative MTU for Overlay

#endif // GIANTVM_CONFIG_H
```

**æ–‡ä»¶**: `common_include/platform_defs.h`

```c
#ifndef PLATFORM_DEFS_H
#define PLATFORM_DEFS_H

#ifdef __KERNEL__
    /* Kernel Space Shim */
    #include <linux/types.h>
    #include <linux/vmalloc.h>
    #include <linux/slab.h>
    #include <linux/errno.h>
    #include <linux/string.h>
    #include <linux/atomic.h>
    #include <asm/processor.h> // for cpu_relax
#else
    /* User Space Shim */
    #include <stdint.h>
    #include <stdlib.h>
    #include <stdio.h>
    #include <string.h>
    #include <errno.h>
#endif

#endif // PLATFORM_DEFS_H
```

**æ–‡ä»¶**: `common_include/giantvm_protocol.h`

```c
#ifndef GIANTVM_PROTOCOL_H
#define GIANTVM_PROTOCOL_H

#include "giantvm_config.h"
#include "platform_defs.h"

// [ä¿ç•™] åŸæœ‰çš„ç½‘ç»œåè®®éƒ¨åˆ†
enum {
    MSG_PING = 0,
    MSG_MEM_READ = 1,
    MSG_MEM_WRITE = 2,
    MSG_MEM_ACK = 3,
    MSG_COPYSET_UPDATE = 4,
    MSG_VCPU_EXIT = 5
};

enum {
    REQ_PENDING = 0,
    REQ_DONE = 1
};

struct gvm_header {
    uint32_t magic;
    uint16_t msg_type;
    uint32_t slave_id;
    uint64_t req_id;
    uint32_t frag_seq;
    uint8_t  is_frag;
} __attribute__((packed));

typedef struct {
    unsigned long bits[(GVM_MAX_SLAVES + 63) / 64];
} copyset_t;


// [æ–°å¢] Mode B (User Mode) IPC åè®®å®šä¹‰
// ---------------------------------------------------------
#define GVM_USER_SOCK_PATH "/tmp/giantvm.sock"
#define GVM_USER_SHM_PATH  "/dev/shm/giantvm_ram"

// QEMU -> Master: "è¿™ä¸ªåœ°å€ç¼ºé¡µäº†ï¼Œè¯·å¡«å……"
struct gvm_ipc_fault_req {
    uint64_t gpa;      // ç¼ºé¡µçš„ Guest Physical Address
    uint64_t len;      // ç¼ºé¡µé•¿åº¦ (é€šå¸¸æ˜¯ 4096)
};

// Master -> QEMU: "æ•°æ®å·²å¡«å……å®Œæ¯•ï¼Œå¯ä»¥å”¤é†’ vCPU äº†"
struct gvm_ipc_fault_ack {
    uint64_t gpa;      // ç¡®è®¤å®Œæˆçš„åœ°å€
    int status;    // 0 = OK, <0 = Error
};
// ---------------------------------------------------------


#endif // GIANTVM_PROTOCOL_H
```

**æ–‡ä»¶**: `common_include/giantvm_ioctl.h`

```c
#ifndef GIANTVM_IOCTL_H
#define GIANTVM_IOCTL_H

#include <linux/ioctl.h>

struct gvm_ioctl_gateway {
    uint32_t gw_id;
    uint32_t ip;   // Network byte order
    uint16_t port; // Network byte order
};

// Control Plane Injection
#define IOCTL_SET_GATEWAY _IOW('G', 1, struct gvm_ioctl_gateway)

#endif // GIANTVM_IOCTL_H
```

---

## Step 2: ç»Ÿä¸€é©±åŠ¨æ¥å£ (Unified Driver)

**æ–‡ä»¶**: `master_core/unified_driver.h`

```c
#ifndef UNIFIED_DRIVER_H
#define UNIFIED_DRIVER_H

#include "../common_include/platform_defs.h"

/*
 * Abstract Interface for Kernel/User Dual Mode
 * Implements the "Survival Rules" abstraction.
 */
struct dsm_driver_ops {
    // --- Memory Management (Infinite Scale) ---
    void* (*alloc_large_table)(size_t size);       // Use vzalloc(Kernel) / calloc(User)
    void  (*free_large_table)(void *ptr);
    void* (*alloc_packet)(size_t size, int atomic);// Use kmalloc/slab(Kernel) / malloc(User)
    void  (*free_packet)(void *ptr);

    // --- Control Plane ---
    void  (*set_gateway_ip)(uint32_t gw_id, uint32_t ip, uint16_t port);

    // --- Data Plane ---
    int   (*send_packet)(void *data, int len, uint32_t target_id);
    
    // [Updated] ç¼ºé¡µå›è°ƒç°åœ¨å…è®¸å¤±è´¥è¿”å› int
    int   (*handle_page_fault)(uint64_t gpa, void *page_buffer); 

    // --- Utilities & Logging ---
    void  (*log)(const char *fmt, ...);
    int   (*is_atomic_context)(void);
    void  (*touch_watchdog)(void); // touch_nmi_watchdog()

    // --- RUDP Reliability & Atomic Primitives (High Performance Ring Buffer) ---
    // [Updated] O(1) ID Allocation (Replaces atomic_inc_id)
    // Returns 0xFFFF... if full. 'rx_buffer' is where received data will be copied.
    uint64_t (*alloc_req_id)(void *rx_buffer); 
    void     (*free_req_id)(uint64_t id);

    uint64_t (*get_time_us)(void);             // High precision timer
    uint64_t (*time_diff_us)(uint64_t start);  // Handle overflow
    
    // Check Status MUST include memory barrier (smp_rmb)
    int      (*check_req_status)(uint64_t id); 
    
    // CPU Yielding instructions
    void     (*cpu_relax)(void);               
};

extern struct dsm_driver_ops *g_ops;

#endif // UNIFIED_DRIVER_H
```

---

## Step 3: çº¯é€»è¾‘æ ¸å¿ƒ (Logic Core)

**æ–‡ä»¶**: `master_core/logic_core.h`

```c
#ifndef LOGIC_CORE_H
#define LOGIC_CORE_H

#include "unified_driver.h"

int gvm_core_init(struct dsm_driver_ops *ops);
void gvm_handle_page_fault_logic(uint64_t gpa);

#endif // LOGIC_CORE_H
```

**æ–‡ä»¶**: `master_core/logic_core.c`

```c
#include "logic_core.h"
#include "../common_include/giantvm_protocol.h"
#include "../common_include/giantvm_config.h"

struct dsm_driver_ops *g_ops = NULL;

// ---------------------------------------------------------
// 1. Initialization
// ---------------------------------------------------------
int gvm_core_init(struct dsm_driver_ops *ops) {
    if (!ops) return -1;
    g_ops = ops;

    size_t table_size = sizeof(uint8_t) * GVM_MAX_SLAVES;
    void *node_table = g_ops->alloc_large_table(table_size);
    
    if (!node_table) {
        g_ops->log("CRITICAL: Failed to allocate node table. Size: %lu", table_size);
        return -ENOMEM;
    }

    g_ops->log("GiantVM Core Initialized. Scale: %lu nodes", GVM_MAX_SLAVES);
    return 0;
}

// ---------------------------------------------------------
// 2. Routing Logic
// ---------------------------------------------------------
static inline uint32_t get_gateway_id(uint32_t slave_id) {
    return slave_id >> GVM_ROUTING_SHIFT;
}

// ---------------------------------------------------------
// 3. Reliability: Thread-Safe RUDP with Buffer Fill
// ---------------------------------------------------------
// rx_buffer: å¦‚æœéç©ºï¼Œæ”¶åˆ°çš„æ•°æ®ä¼šè¢«ç›´æ¥å†™å…¥æ­¤åœ°å€
int gvm_rpc_call(uint16_t msg_type, void *payload, int len, uint32_t target_id, void *rx_buffer) {
    if (!g_ops) return -ENODEV;

    // A. Alloc ID (O(1)) and register buffer
    uint64_t rid = g_ops->alloc_req_id(rx_buffer);
    if (rid == (uint64_t)-1) return -EBUSY; // Ring Buffer Full
    
    size_t pkt_len = sizeof(struct gvm_header) + len;
    uint8_t *buffer = g_ops->alloc_packet(pkt_len, 1);
    if (!buffer) {
        g_ops->free_req_id(rid);
        return -ENOMEM;
    }

    struct gvm_header *hdr = (struct gvm_header *)buffer;
    hdr->magic = GVM_MAGIC;
    hdr->msg_type = msg_type;
    hdr->slave_id = target_id;
    hdr->req_id = rid;
    hdr->is_frag = 0; 
    hdr->frag_seq = 0;

    if (payload && len > 0) {
        memcpy(buffer + sizeof(struct gvm_header), payload, len);
    }

    // B. Send & Wait
    g_ops->send_packet(buffer, pkt_len, target_id);
    uint64_t start = g_ops->get_time_us();
    
    uint64_t timeout = 2000; 
    int retries = 0;
    int result = 0;

    while (g_ops->check_req_status(rid) != REQ_DONE) {
        g_ops->touch_watchdog();

        if (g_ops->time_diff_us(start) > timeout) {
            if (++retries > 50) {
                g_ops->log("RPC Timeout: id=%lu, slave=%u down?", rid, target_id);
                result = -EIO;
                goto out;
            }
            g_ops->send_packet(buffer, pkt_len, target_id);
            timeout *= 2;
            if (timeout > 100000) timeout = 100000;
            start = g_ops->get_time_us();
        }
        g_ops->cpu_relax();
    }

out:
    g_ops->free_req_id(rid);
    g_ops->free_packet(buffer);
    return result;
}

// ---------------------------------------------------------
// 4. Fault Handler Interface
// ---------------------------------------------------------
// [Updated] Returns int, takes page_buffer
int gvm_handle_page_fault_logic(uint64_t gpa, void *page_buffer) {
    uint32_t target_slave = (uint32_t)((gpa >> 12) % GVM_MAX_SLAVES);
    
    // Blocking RPC call, requesting data to be written to page_buffer
    return gvm_rpc_call(MSG_MEM_READ, &gpa, sizeof(gpa), target_slave, page_buffer);
}
```

---

## Step 4: å†…æ ¸åç«¯å®ç°ä¸å†…æ ¸æ„å»ºè„šæœ¬ (Kernel Backend & Kernel Build Script)

**æ–‡ä»¶**: `master_core/kernel_backend.c`

```c
#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/init.h>
#include <linux/fs.h>
#include <linux/mm.h>
#include <linux/miscdevice.h>
#include <linux/net.h>
#include <linux/in.h>
#include <linux/udp.h>
#include <linux/socket.h>
#include <linux/slab.h>
#include <linux/vmalloc.h> // å¿…é¡»åŒ…å«ï¼Œç”¨äº vzalloc
#include <linux/uaccess.h>
#include <linux/ktime.h>
#include <linux/nmi.h>      
#include <linux/delay.h>    
#include <linux/sched.h>
#include <linux/atomic.h>
#include <asm/barrier.h>    
#include <linux/spinlock.h>

#include "../common_include/giantvm_ioctl.h"
#include "../common_include/giantvm_protocol.h"
#include "unified_driver.h"
#include "logic_core.h"

#define DRIVER_NAME "giantvm"
/* 
 * [FIX] Increased to 128k (2^17) to prevent ID reuse during congestion.
 * Must be a power of 2 for bitwise masking optimization.
 */
#define MAX_INFLIGHT_REQS 131072 

// å®šä¹‰å”¯ä¸€çš„ Slab ç¼“å­˜åç§°
#define GVM_PACKET_CACHE_NAME "gvm_pkt_v16"

// ---------------------------------------------------------
// 1. Global State & Ring Buffer Definition
// ---------------------------------------------------------
static struct socket *g_socket = NULL;
static struct sockaddr_in gateway_table[GVM_MAX_GATEWAYS]; 
static struct kmem_cache *gvm_cache = NULL;

// [High Performance Ring Buffer for ID Allocation]
struct id_pool_t {
    uint32_t *ids; // [FIX] Changed to pointer for dynamic allocation
    uint32_t head;
    uint32_t tail;
    spinlock_t lock;
};
static struct id_pool_t g_id_pool;

// [Request Context]
// å­˜å‚¨æ¯ä¸ª ID å¯¹åº”çš„æ¥æ”¶ç¼“å†²åŒºæŒ‡é’ˆå’Œå®ŒæˆçŠ¶æ€
struct req_ctx_t {
    void *rx_buffer;       
    volatile int done;     
};
// [FIX] Changed to pointer for dynamic allocation
static struct req_ctx_t *g_req_ctx = NULL;

// ---------------------------------------------------------
// 2. ID Allocation (O(1) Implementation)
// ---------------------------------------------------------
// æ³¨æ„ï¼šåˆå§‹åŒ–é€»è¾‘å·²ç§»è‡³ giantvm_init ä¸­è¿›è¡Œç»Ÿä¸€å†…å­˜ç®¡ç†

static uint64_t k_alloc_req_id(void *rx_buffer) {
    uint64_t id = (uint64_t)-1;
    unsigned long flags;

    spin_lock_irqsave(&g_id_pool.lock, flags);
    
    // æ£€æŸ¥æ˜¯å¦æœ‰ç©ºé—² ID (tail > head)
    if (g_id_pool.tail != g_id_pool.head) {
        // Pop ID
        // [FIX] ids is now uint32_t*, safe access
        uint32_t raw_id = g_id_pool.ids[g_id_pool.head & (MAX_INFLIGHT_REQS - 1)];
        g_id_pool.head++;
        id = (uint64_t)raw_id;
        
        // Setup Context
        g_req_ctx[id].rx_buffer = rx_buffer;
        g_req_ctx[id].done = 0;
    }

    spin_unlock_irqrestore(&g_id_pool.lock, flags);
    return id;
}

static void k_free_req_id(uint64_t id) {
    unsigned long flags;
    if (id >= MAX_INFLIGHT_REQS) return;

    spin_lock_irqsave(&g_id_pool.lock, flags);
    
    // Push ID back
    // [FIX] ids is now uint32_t*
    g_id_pool.ids[g_id_pool.tail & (MAX_INFLIGHT_REQS - 1)] = (uint32_t)id;
    g_id_pool.tail++;
    
    // Clear Context
    g_req_ctx[id].rx_buffer = NULL;
    g_req_ctx[id].done = 0;

    spin_unlock_irqrestore(&g_id_pool.lock, flags);
}

static int k_check_req_status(uint64_t id) {
    smp_rmb(); // è¯»å±éšœ
    // [FIX] å¢åŠ è¾¹ç•Œæ£€æŸ¥
    if (id >= MAX_INFLIGHT_REQS) return -1;
    return g_req_ctx[id].done;
}

// ---------------------------------------------------------
// 3. Helper Functions
// ---------------------------------------------------------
static uint64_t k_get_time_us(void) {
    return ktime_to_us(ktime_get());
}

static uint64_t k_time_diff_us(uint64_t start) {
    uint64_t now = k_get_time_us();
    if (now >= start) return now - start;
    return (uint64_t)(-1) - start + now;
}

static void k_cpu_relax(void) {
    cpu_relax();
}

static void k_touch_watchdog(void) {
    touch_nmi_watchdog();
    #ifdef CONFIG_LOCKUP_DETECTOR
    touch_softlockup_watchdog();
    #endif
}

static int k_is_atomic_context(void) {
    return in_atomic() || irqs_disabled();
}

static void k_log(const char *fmt, ...) {
    va_list args;
    va_start(args, fmt);
    vprintk(fmt, args);
    va_end(args);
}

// ---------------------------------------------------------
// 4. Network Receive (Data Copy Logic)
// ---------------------------------------------------------
static void giantvm_udp_data_ready(struct sock *sk) {
    struct sk_buff *skb;
    unsigned long flags;
    
    while ((skb = skb_dequeue(&sk->sk_receive_queue)) != NULL) {
        if (skb->len >= sizeof(struct gvm_header)) {
            struct gvm_header *hdr = (struct gvm_header *)skb->data;
            
            if (hdr->magic == GVM_MAGIC) {
                uint64_t rid = hdr->req_id;
                
                if (rid < MAX_INFLIGHT_REQS) {
                    spin_lock_irqsave(&g_id_pool.lock, flags);

                    if (g_req_ctx[rid].rx_buffer) {
                        int payload_len = skb->len - sizeof(struct gvm_header);
                        if (payload_len > 0) {
                            memcpy(g_req_ctx[rid].rx_buffer, 
                                   skb->data + sizeof(struct gvm_header), 
                                   payload_len);
                        }
                        g_req_ctx[rid].done = 1;
                    }
                    
                    spin_unlock_irqrestore(&g_id_pool.lock, flags);
                }
            }
        }
        kfree_skb(skb);
    }
}

// ---------------------------------------------------------
// 5. Memory Management
// ---------------------------------------------------------
static void* k_alloc_large_table(size_t size) {
    return vzalloc(size); 
}

static void k_free_large_table(void *ptr) {
    vfree(ptr);
}

static void* k_alloc_packet(size_t size, int atomic) {
    if (!gvm_cache) return NULL;
    return kmem_cache_alloc(gvm_cache, atomic ? GFP_ATOMIC : GFP_KERNEL);
}

static void k_free_packet(void *ptr) {
    if (ptr) kmem_cache_free(gvm_cache, ptr);
}

// ---------------------------------------------------------
// 6. Network Send (Non-blocking retry)
// ---------------------------------------------------------
static int k_send_packet(void *data, int len, uint32_t target_id) {
    struct msghdr msg;
    struct kvec vec;
    struct sockaddr_in to_addr;
    int ret = 0;
    int offset = 0;
    uint32_t gw_id = target_id >> GVM_ROUTING_SHIFT;
    struct gvm_header *hdr = (struct gvm_header *)data;
    
    if (!g_socket) return -ENODEV;

    memset(&to_addr, 0, sizeof(to_addr));
    to_addr.sin_family = AF_INET;
    to_addr.sin_addr.s_addr = gateway_table[gw_id].ip;
    to_addr.sin_port = gateway_table[gw_id].port;

    int frag_count = 0;
    while (offset < len) {
        int chunk_len = len - offset;
        if (chunk_len > MTU_SIZE) chunk_len = MTU_SIZE;

        if (len > MTU_SIZE) {
            hdr->is_frag = 1;
            hdr->frag_seq = frag_count++;
        }

        memset(&msg, 0, sizeof(msg));
        msg.msg_name = &to_addr;
        msg.msg_namelen = sizeof(to_addr);

        vec.iov_base = data + offset;
        vec.iov_len = chunk_len;

        // [Survival Rule] Deadlock Protection
        if (k_is_atomic_context()) {
            int retries = 0;
            msg.msg_flags = MSG_DONTWAIT;
            
            while (retries < 1000) {
                ret = kernel_sendmsg(g_socket, &msg, &vec, 1, chunk_len);
                if (ret == chunk_len) break;
                
                k_touch_watchdog();
                udelay(10); 
                retries++;
            }
            if (retries >= 1000) return -EBUSY;
        } else {
            ret = kernel_sendmsg(g_socket, &msg, &vec, 1, chunk_len);
            if (ret < 0) return ret;
        }
        offset += chunk_len;
    }
    return 0;
}

static void k_set_gateway_ip(uint32_t gw_id, uint32_t ip, uint16_t port) {
    if (gw_id < GVM_MAX_GATEWAYS) {
        gateway_table[gw_id].ip = ip;
        gateway_table[gw_id].port = port;
    }
}

// ---------------------------------------------------------
// 7. Ops Binding
// ---------------------------------------------------------
static struct dsm_driver_ops k_ops = {
    .alloc_large_table = k_alloc_large_table,
    .free_large_table = k_free_large_table,
    .alloc_packet = k_alloc_packet,
    .free_packet = k_free_packet,
    .set_gateway_ip = k_set_gateway_ip,
    .send_packet = k_send_packet,
    .handle_page_fault = NULL, 
    .log = k_log,
    .is_atomic_context = k_is_atomic_context,
    .touch_watchdog = k_touch_watchdog,
    .alloc_req_id = k_alloc_req_id,
    .free_req_id = k_free_req_id,
    .get_time_us = k_get_time_us,
    .time_diff_us = k_time_diff_us,
    .check_req_status = k_check_req_status,
    .cpu_relax = k_cpu_relax
};

// ---------------------------------------------------------
// 8. Page Fault Handler
// ---------------------------------------------------------
static vm_fault_t gvm_fault_handler(struct vm_fault *vmf) {
    struct page *page;
    void *page_addr;
    int ret;
    uint64_t gpa = (uint64_t)vmf->pgoff << PAGE_SHIFT;

    page = alloc_page(GFP_HIGHUSER_MOVABLE | __GFP_ZERO);
    if (!page) return VM_FAULT_OOM;

    page_addr = page_address(page);

    if (gvm_handle_page_fault_logic(gpa, page_addr) < 0) {
        __free_page(page);
        return VM_FAULT_SIGBUS; 
    }

    ret = vm_insert_page(vmf->vma, vmf->address, page);
    
    if (likely(ret == 0)) {
        put_page(page); 
        return VM_FAULT_NOPAGE;
    } else {
        __free_page(page);
        return VM_FAULT_SIGBUS;
    }
}

static const struct vm_operations_struct gvm_vm_ops = {
    .fault = gvm_fault_handler,
};

static int gvm_mmap(struct file *filp, struct vm_area_struct *vma) {
    vma->vm_ops = &gvm_vm_ops;
    vma->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP | VM_IO; 
    return 0;
}

static long gvm_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) {
    struct gvm_ioctl_gateway data;
    switch (cmd) {
        case IOCTL_SET_GATEWAY:
            if (copy_from_user(&data, (void __user *)arg, sizeof(data)))
                return -EFAULT;
            k_set_gateway_ip(data.gw_id, data.ip, data.port);
            break;
        default: return -EINVAL;
    }
    return 0;
}

static const struct file_operations gvm_fops = {
    .owner = THIS_MODULE,
    .mmap = gvm_mmap,
    .unlocked_ioctl = gvm_ioctl,
    .open = nonseekable_open,
};

static struct miscdevice gvm_misc = {
    .minor = MISC_DYNAMIC_MINOR,
    .name = "giantvm",
    .fops = &gvm_fops,
};

// ---------------------------------------------------------
// 9. Init/Exit
// ---------------------------------------------------------
static int __init giantvm_init(void) {
    int ret;
    uint32_t i;

    // [FIX] åŠ¨æ€åˆ†é…å¤§å†…å­˜ï¼Œé¿å… BSS æ®µçˆ†ç‚¸
    g_id_pool.ids = vzalloc(sizeof(uint32_t) * MAX_INFLIGHT_REQS);
    g_req_ctx = vzalloc(sizeof(struct req_ctx_t) * MAX_INFLIGHT_REQS);

    if (!g_id_pool.ids || !g_req_ctx) {
        if (g_id_pool.ids) vfree(g_id_pool.ids);
        if (g_req_ctx) vfree(g_req_ctx);
        printk(KERN_ERR "GiantVM: Failed to allocate ID pool memory.\n");
        return -ENOMEM;
    }

    // åˆå§‹åŒ– ID æ± 
    spin_lock_init(&g_id_pool.lock);
    g_id_pool.head = 0;
    g_id_pool.tail = MAX_INFLIGHT_REQS;
    for (i = 0; i < MAX_INFLIGHT_REQS; i++) {
        g_id_pool.ids[i] = i; // uint32_t èµ‹å€¼ï¼Œæ— æº¢å‡ºé£é™©
        g_req_ctx[i].rx_buffer = NULL;
        g_req_ctx[i].done = 0;
    }

    // 1. Init Logic Core
    if (gvm_core_init(&k_ops) != 0) {
        vfree(g_id_pool.ids);
        vfree(g_req_ctx);
        return -ENOMEM;
    }

    // 2. Create Slab
    gvm_cache = kmem_cache_create(GVM_PACKET_CACHE_NAME, 2048, 0, SLAB_HWCACHE_ALIGN, NULL);
    if (!gvm_cache) {
        printk(KERN_ERR "GiantVM: Failed to create slab cache %s\n", GVM_PACKET_CACHE_NAME);
        vfree(g_id_pool.ids);
        vfree(g_req_ctx);
        return -ENOMEM;
    }

    // 3. Register Device
    if ((ret = misc_register(&gvm_misc))) {
        kmem_cache_destroy(gvm_cache); 
        vfree(g_id_pool.ids);
        vfree(g_req_ctx);
        return ret;
    }

    // 4. Create Socket
    if ((ret = sock_create_kern(&init_net, AF_INET, SOCK_DGRAM, IPPROTO_UDP, &g_socket)) < 0) {
        misc_deregister(&gvm_misc);
        kmem_cache_destroy(gvm_cache); 
        vfree(g_id_pool.ids);
        vfree(g_req_ctx);
        return ret;
    }

    // 5. RX Hook
    if (g_socket->sk) {
        g_socket->sk->sk_data_ready = giantvm_udp_data_ready;
    }

    printk(KERN_INFO "GiantVM: Frontier-X Backend Loaded. Pool Size: %d\n", MAX_INFLIGHT_REQS);
    return 0;
}

static void __exit giantvm_exit(void) {
    // 1. åœæ­¢ç½‘ç»œæ¥æ”¶
    if (g_socket) {
        g_socket->sk->sk_data_ready = NULL;
        sock_release(g_socket);
    }
    
    // 2. æ³¨é”€è®¾å¤‡
    misc_deregister(&gvm_misc);
    
    // 3. é”€æ¯ Slab
    if (gvm_cache) {
        kmem_cache_destroy(gvm_cache);
    }

    // 4. [FIX] é‡Šæ”¾åŠ¨æ€åˆ†é…çš„å†…å­˜
    if (g_id_pool.ids) vfree(g_id_pool.ids);
    if (g_req_ctx) vfree(g_req_ctx);
    
    printk(KERN_INFO "GiantVM: Unloaded.\n");
}

module_init(giantvm_init);
module_exit(giantvm_exit);
MODULE_LICENSE("GPL");
```

**æ–‡ä»¶**: `master_core/Kbuild`

```makefile
# å®šä¹‰æ¨¡å—åç§°
obj-m += giantvm.o

# å®šä¹‰æ¨¡å—åŒ…å«çš„ç›®æ ‡æ–‡ä»¶
# å°†é€»è¾‘æ ¸å¿ƒ (Logic Core) å’Œå†…æ ¸åç«¯ (Kernel Backend) é“¾æ¥ä¸ºä¸€ä¸ª .ko æ–‡ä»¶
giantvm-y := kernel_backend.o logic_core.o

# æ·»åŠ å…¬å…±å¤´æ–‡ä»¶è·¯å¾„
# $(src) æ˜¯å†…æ ¸æ„å»ºç³»ç»Ÿæä¾›çš„å˜é‡ï¼ŒæŒ‡å‘å½“å‰ç›®å½•
ccflags-y := -I$(src)/../common_include
```

---

## Step 5: ç”¨æˆ·æ€åç«¯å®ç° (User Backend)

**æ–‡ä»¶**: `master_core/user_backend.c`

```c
#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <arpa/inet.h>
#include <sys/socket.h>
#include <sys/time.h>
#include <stdarg.h>
#include <errno.h>
#include <pthread.h>
#include <fcntl.h>
#include <sched.h> // [FIX] Added for sched_yield

#include "unified_driver.h"
#include "../common_include/giantvm_protocol.h"

#define MAX_INFLIGHT_REQS 65536
#define MASTER_PORT 8000 
// [FIX] Adaptive Spin Constant
#define ADAPTIVE_SPIN_COUNT 2000

// ---------------------------------------------------------
// 1. Global State
// ---------------------------------------------------------
static int g_sock = -1;
static struct sockaddr_in g_gateways[GVM_MAX_GATEWAYS];
static pthread_t g_rx_thread;

// ---------------------------------------------------------
// 2. Thread-Safe Request Context
// ---------------------------------------------------------
struct u_req_ctx_t {
    void *rx_buffer;
    int  status;          // State (REQ_PENDING, REQ_DONE)
    pthread_mutex_t lock;   // Mutex per-request
};
static struct u_req_ctx_t g_u_req_ctx[MAX_INFLIGHT_REQS];
static uint64_t g_id_counter = 0;

// ---------------------------------------------------------
// 3. Malloc Wrappers
// ---------------------------------------------------------
static void* u_alloc_large_table(size_t size) { return calloc(1, size); }
static void u_free_large_table(void *ptr) { free(ptr); }
static void* u_alloc_packet(size_t size, int atomic) { return malloc(size); }
static void u_free_packet(void *ptr) { free(ptr); }

// ---------------------------------------------------------
// 4. ID Allocation with Context Setup
// ---------------------------------------------------------
static uint64_t u_alloc_req_id(void *rx_buffer) {
    uint64_t id;
    
    /* åŸå­æ“ä½œè·å–å…¨å±€å”¯ä¸€idï¼ŒåŒæ—¶åˆå§‹åŒ–reqä¸Šä¸‹æ–‡ */
    id = __sync_fetch_and_add(&g_id_counter, 1);
    
    /* å‡†å¤‡idå¯¹åº”reqä¸Šä¸‹æ–‡ä¿¡æ¯ */
    pthread_mutex_lock(&g_u_req_ctx[id % MAX_INFLIGHT_REQS].lock);
    g_u_req_ctx[id % MAX_INFLIGHT_REQS].rx_buffer = rx_buffer;
    g_u_req_ctx[id % MAX_INFLIGHT_REQS].status = 0;
    pthread_mutex_unlock(&g_u_req_ctx[id % MAX_INFLIGHT_REQS].lock);

    return id;
}

static void u_free_req_id(uint64_t id) {
    pthread_mutex_lock(&g_u_req_ctx[id % MAX_INFLIGHT_REQS].lock);
    g_u_req_ctx[id % MAX_INFLIGHT_REQS].rx_buffer = NULL;
    pthread_mutex_unlock(&g_u_req_ctx[id % MAX_INFLIGHT_REQS].lock);
}

// ---------------------------------------------------------
// 5. Network Receive
// ---------------------------------------------------------
static void* rx_thread_loop(void *arg) {
    char buf[MTU_SIZE];
    struct sockaddr_in src_addr;
    socklen_t addr_len = sizeof(src_addr);

    while (1) {
        int len = recvfrom(g_sock, buf, sizeof(buf), 0, (struct sockaddr*)&src_addr, &addr_len);
        if (len >= sizeof(struct gvm_header)) {
            struct gvm_header *hdr = (struct gvm_header *)buf;
            uint32_t idx = hdr->req_id % MAX_INFLIGHT_REQS;

            // éªŒè¯è¯·æ±‚
            if (hdr->magic == GVM_MAGIC && (hdr->msg_type == MSG_MEM_ACK || hdr->msg_type == MSG_VCPU_EXIT)) {
                 // ç¡®ä¿äº’æ–¥è®¿é—®ä¸Šä¸‹æ–‡ä¿¡æ¯
                pthread_mutex_lock(&g_u_req_ctx[idx].lock);
                if (g_u_req_ctx[idx].rx_buffer != NULL) {
                    // æ‰§è¡Œæ•°æ®æ‹·è´
                    int payload_len = len - sizeof(struct gvm_header);
                    if (payload_len > 0) {
                        memcpy(g_u_req_ctx[idx].rx_buffer, buf + sizeof(struct gvm_header), payload_len);
                    }
                    g_u_req_ctx[idx].status = 1;  // æ ‡è®°ä¸ºå®Œæˆ
                }
                pthread_mutex_unlock(&g_u_req_ctx[idx].lock);
            }
        }
    }
    return NULL;
}

// ---------------------------------------------------------
// 6. Send
// ---------------------------------------------------------
static void u_set_gateway_ip(uint32_t gw_id, uint32_t ip, uint16_t port) {
    if (gw_id < GVM_MAX_GATEWAYS) {
        g_gateways[gw_id].sin_family = AF_INET;
        g_gateways[gw_id].sin_addr.s_addr = ip;
        g_gateways[gw_id].sin_port = port;
    }
}

static int u_send_packet(void *data, int len, uint32_t target_id) {
    if (g_sock < 0) return -1;
    struct gvm_header *hdr = (struct gvm_header *)data;
    uint32_t gw_id = target_id >> GVM_ROUTING_SHIFT;
    struct sockaddr_in *addr = &g_gateways[gw_id];

    if (addr->sin_port == 0) return -1;

    // æ¸…é™¤çŠ¶æ€ä½
    uint32_t idx = hdr->req_id % MAX_INFLIGHT_REQS;
    pthread_mutex_lock(&g_u_req_ctx[idx].lock);
    g_u_req_ctx[idx].status = 0;
    pthread_mutex_unlock(&g_u_req_ctx[idx].lock);
    
    return sendto(g_sock, data, len, 0, (struct sockaddr*)addr, sizeof(*addr));
}

// ---------------------------------------------------------
// 7. Logic Hooks
// ---------------------------------------------------------
static int u_check_req_status(uint64_t id) {
    int status;
    uint32_t idx = id % MAX_INFLIGHT_REQS;

    pthread_mutex_lock(&g_u_req_ctx[idx].lock);
    status = g_u_req_ctx[idx].status;
    pthread_mutex_unlock(&g_u_req_ctx[idx].lock);

    return status;
}

static void u_log(const char *fmt, ...) {
    va_list args;
    va_start(args, fmt);
    vfprintf(stderr, fmt, args);
    fprintf(stderr, "\n");
    va_end(args);
}
static int u_is_atomic_context(void) { return 0; }
static void u_touch_watchdog(void) { }
static uint64_t u_get_time_us(void) {
    struct timeval tv; gettimeofday(&tv, NULL);
    return tv.tv_sec * 1000000UL + tv.tv_usec;
}
static uint64_t u_time_diff_us(uint64_t start) { return u_get_time_us() - start; }

// [FIX] Adaptive Spinning Strategy
static void u_cpu_relax(void) {
    static __thread int spin_counter = 0;

    // Phase 1: Fast Spin (Low Latency for local/fast network)
    if (spin_counter++ < ADAPTIVE_SPIN_COUNT) {
#if defined(__x86_64__) || defined(__i386__)
        __builtin_ia32_pause(); 
#elif defined(__aarch64__)
        __asm__ volatile("yield");
#endif
        return; 
    }

    // Phase 2: Yield CPU (Avoid burning CPU on congestion)
    spin_counter = 0; 
    sched_yield(); 
}

// ---------------------------------------------------------
// 8. Ops Binding
// ---------------------------------------------------------
struct dsm_driver_ops u_ops = {
    .alloc_large_table = u_alloc_large_table,
    .free_large_table = u_free_large_table,
    .alloc_packet = u_alloc_packet,
    .free_packet = u_free_packet,
    .set_gateway_ip = u_set_gateway_ip,
    .send_packet = u_send_packet,
    .handle_page_fault = NULL, 
    .log = u_log,
    .is_atomic_context = u_is_atomic_context,
    .touch_watchdog = u_touch_watchdog,
    .alloc_req_id = u_alloc_req_id,
    .free_req_id = u_free_req_id,
    .get_time_us = u_get_time_us,
    .time_diff_us = u_time_diff_us,
    .check_req_status = u_check_req_status,
    .cpu_relax = u_cpu_relax
};

// ---------------------------------------------------------
// 9. Init
// ---------------------------------------------------------
int user_backend_init(void) {
    g_sock = socket(AF_INET, SOCK_DGRAM, 0);
    if (g_sock < 0) return -1;

    // è®¾ç½®å¥—æ¥å­—ä¸ºéé˜»å¡æ¨¡å¼
    int flags = fcntl(g_sock, F_GETFL, 0);
    if (flags == -1) {
        perror("fcntl(F_GETFL) failed");
        close(g_sock);
        return -1;
    }

    if (fcntl(g_sock, F_SETFL, flags | O_NONBLOCK) == -1) {
        perror("fcntl(F_SETFL) failed");
        close(g_sock);
        return -1;
    }

    // [å…³é”®] ç»‘å®šå›ºå®šç«¯å£
    struct sockaddr_in bind_addr;
    memset(&bind_addr, 0, sizeof(bind_addr));
    bind_addr.sin_family = AF_INET;
    bind_addr.sin_addr.s_addr = INADDR_ANY;
    bind_addr.sin_port = htons(MASTER_PORT);

    if (bind(g_sock, (struct sockaddr*)&bind_addr, sizeof(bind_addr)) < 0) {
        perror("[-] Failed to bind Master Port");
        close(g_sock);
        return -1;
    }

    // åˆå§‹åŒ–è¯·æ±‚ä¸Šä¸‹æ–‡
    for (int i = 0; i < MAX_INFLIGHT_REQS; i++) {
        g_u_req_ctx[i].rx_buffer = NULL;
        pthread_mutex_init(&g_u_req_ctx[i].lock, NULL);
    }
    if (pthread_create(&g_rx_thread, NULL, rx_thread_loop, NULL) != 0) return -1;
    return 0;
}
```

**æ–‡ä»¶**: `master_core/main_wrapper.c`

```c
#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <arpa/inet.h>
#include <sys/socket.h>
#include <sys/un.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <errno.h>

#include "logic_core.h"
#include "../common_include/giantvm_protocol.h"

// å¼•ç”¨å¤–éƒ¨å®šä¹‰çš„ User Mode Ops
extern struct dsm_driver_ops u_ops;
extern int user_backend_init(void);

// å…¨å±€å˜é‡
static void *g_shm_ptr = NULL; // æŒ‡å‘å…±äº«å†…å­˜çš„æŒ‡é’ˆ
static size_t g_shm_size = 0;

// å¤„ç†æ¥è‡ª QEMU çš„å•ä¸ªç¼ºé¡µè¯·æ±‚
static void handle_qemu_request(int qemu_fd, struct gvm_ipc_fault_req *req) {
    struct gvm_ipc_fault_ack ack;
    ack.gpa = req->gpa;
    
    // è®¡ç®—ç¼ºé¡µåœ°å€åœ¨å…±äº«å†…å­˜ä¸­çš„åç§»
    // æ³¨æ„: è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ï¼Œå®é™…åº”å¤„ç†å¤šä¸ª memory slot
    void *target_page_addr = g_shm_ptr + req->gpa;

    // è°ƒç”¨æ ¸å¿ƒé€»è¾‘ï¼Œå°†è¿œç«¯æ•°æ®ç›´æ¥å¡«å……åˆ°å…±äº«å†…å­˜é¡µ
    int ret = gvm_handle_page_fault_logic(req->gpa, target_page_addr);
    
    ack.status = ret;
    
    // å‘é€ ACK ç»™ QEMUï¼Œé€šçŸ¥å®ƒæ•°æ®å·²å‡†å¤‡å¥½
    if (write(qemu_fd, &ack, sizeof(ack)) != sizeof(ack)) {
        perror("[-] Failed to send ACK to QEMU");
    }
}

int main(int argc, char **argv) {
    if (argc < 2) {
        fprintf(stderr, "Usage: %s <VM_RAM_in_MB>\n", argv[0]);
        return 1;
    }

    g_shm_size = (size_t)atol(argv[1]) * 1024 * 1024;
    printf("[*] GiantVM User-Mode Master (Mode B) Starting...\n");
    printf("[*] VM RAM Size: %zu MB\n", g_shm_size / 1024 / 1024);

    // 1. åˆå§‹åŒ–ç½‘ç»œåç«¯ (ç”¨äºè¿æ¥ Slaves)
    if (user_backend_init() != 0) {
        fprintf(stderr, "[-] Failed to init user backend\n");
        return 1;
    }
    if (gvm_core_init(&u_ops) != 0) {
        fprintf(stderr, "[-] Failed to init logic core\n");
        return 1;
    }
    
    // ç¤ºä¾‹: é…ç½®ç½‘å…³
    u_ops.set_gateway_ip(0, inet_addr("127.0.0.1"), htons(9000));

    // 2. åˆ›å»ºå¹¶æ˜ å°„å…±äº«å†…å­˜æ–‡ä»¶
    int shm_fd = shm_open(GVM_USER_SHM_PATH, O_CREAT | O_RDWR, 0666);
    if (shm_fd < 0) die("shm_open");
    if (ftruncate(shm_fd, g_shm_size) < 0) die("ftruncate");
    
    g_shm_ptr = mmap(NULL, g_shm_size, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, 0);
    if (g_shm_ptr == MAP_FAILED) die("mmap shared memory");
    close(shm_fd); // fdå¯ä»¥å…³é—­ï¼Œæ˜ å°„ä¾ç„¶æœ‰æ•ˆ
    printf("[+] Shared memory backing file created at %s\n", GVM_USER_SHM_PATH);

    // 3. åˆ›å»ºå¹¶ç›‘å¬ Unix Domain Socket
    int listen_fd = socket(AF_UNIX, SOCK_STREAM, 0);
    if (listen_fd < 0) die("socket unix");
    
    struct sockaddr_un addr;
    memset(&addr, 0, sizeof(addr));
    addr.sun_family = AF_UNIX;
    strncpy(addr.sun_path, GVM_USER_SOCK_PATH, sizeof(addr.sun_path) - 1);
    
    unlink(GVM_USER_SOCK_PATH); // æ¸…ç†æ—§çš„ socket æ–‡ä»¶
    if (bind(listen_fd, (struct sockaddr*)&addr, sizeof(addr)) < 0) die("bind unix");
    if (listen(listen_fd, 1) < 0) die("listen unix");
    printf("[+] Listening for QEMU on %s\n", GVM_USER_SOCK_PATH);

    // 4. ä¸»å¾ªç¯: ç­‰å¾… QEMU è¿æ¥å¹¶å¤„ç†è¯·æ±‚
    while (1) {
        int qemu_fd = accept(listen_fd, NULL, NULL);
        if (qemu_fd < 0) {
            perror("[-] Accept failed");
            continue;
        }
        printf("[+] QEMU process connected!\n");

        // å¾ªç¯å¤„ç†æ¥è‡ªè¿™ä¸ªQEMUå®ä¾‹çš„è¯·æ±‚
        struct gvm_ipc_fault_req req;
        while (read(qemu_fd, &req, sizeof(req)) == sizeof(req)) {
            handle_qemu_request(qemu_fd, &req);
        }
        
        printf("[-] QEMU process disconnected.\n");
        close(qemu_fd);
    }
    
    // æ¸…ç†
    munmap(g_shm_ptr, g_shm_size);
    shm_unlink(GVM_USER_SHM_PATH);
    unlink(GVM_USER_SOCK_PATH);

    return 0;
}
```

**æ–‡ä»¶**: `master_core/Makefile_User`

```makefile
CC = gcc
CFLAGS = -Wall -O2 -I../common_include -pthread
TARGET = giantvm_master_user
SRCS = logic_core.c user_backend.c main_wrapper.c

all: $(TARGET)

$(TARGET): $(SRCS)
	$(CC) $(CFLAGS) -o $@ $^

clean:
	rm -f $(TARGET)
```

---

## Step 6: Slave å®ˆæŠ¤è¿›ç¨‹ (Slave Daemon - Raw io_uring)

**æ–‡ä»¶**: `slave_daemon/net_uring.c`

```c
#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <errno.h>
#include <sched.h> // åŒ…å« CPU äº²å’Œæ€§è®¾ç½®çš„å¤´æ–‡ä»¶
#include "../common_include/giantvm_protocol.h"

// ... (çœç•¥äº† BATCH_SIZE å’Œ RECV_PORT çš„å®å®šä¹‰ï¼Œä¸åŸç‰ˆç›¸åŒ)
#define BATCH_SIZE 64
#define RECV_PORT 9000

// æ¥å£å®šä¹‰ä¿æŒä¸å˜
extern void handle_kvm_request(int sockfd, struct sockaddr_in *addr, struct gvm_header *hdr, void *data);

// åŸæ¥çš„ start_network_loop å‡½æ•°è¢«æ”¹é€ ä¸ºçº¿ç¨‹å…¥å£å‡½æ•°
void* network_thread_worker(void* arg) {
    long core_id = *(long*)arg;
    free(arg); // é‡Šæ”¾ä¼ é€’è¿‡æ¥çš„å‚æ•°å†…å­˜

    // 1. [æ ¸å¿ƒä¼˜åŒ–] ç»‘å®š CPU äº²å’Œæ€§
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(core_id, &cpuset);
    if (pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &cpuset) != 0) {
        // åœ¨æŸäº›å®¹å™¨ç¯å¢ƒä¸­å¯èƒ½å¤±è´¥ï¼Œæ‰“å°è­¦å‘Šä½†ç»§ç»­è¿è¡Œ
        fprintf(stderr, "[Warning] Could not set thread affinity for core %ld\n", core_id);
    } else {
        printf("[Thread %ld] Pinned to CPU Core %ld\n", core_id, core_id);
    }
    
    // 2. æ¯ä¸ªçº¿ç¨‹åˆ›å»ºè‡ªå·±çš„ Socket
    int sockfd = socket(AF_INET, SOCK_DGRAM, 0);
    if (sockfd < 0) {
        perror("socket failed");
        return NULL;
    }

    int opt = 1;
    setsockopt(sockfd, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));
    // 2.1 [æ ¸å¿ƒä¼˜åŒ–] å¼€å¯ SO_REUSEPORT
    // å…è®¸å¤šä¸ª Socket ç»‘å®šåˆ°åŒä¸€ä¸ª IP:PORTï¼Œå†…æ ¸ä¼šè‡ªåŠ¨è¿›è¡Œè´Ÿè½½å‡è¡¡
    if (setsockopt(sockfd, SOL_SOCKET, SO_REUSEPORT, &opt, sizeof(opt)) < 0) {
        perror("SO_REUSEPORT failed. Your kernel might be too old.");
        close(sockfd);
        return NULL;
    }

    struct sockaddr_in addr;
    memset(&addr, 0, sizeof(addr));
    addr.sin_family = AF_INET;
    addr.sin_port = htons(RECV_PORT);
    addr.sin_addr.s_addr = INADDR_ANY;

    if (bind(sockfd, (struct sockaddr *)&addr, sizeof(addr)) < 0) {
        perror("bind failed");
        close(sockfd);
        return NULL;
    }
    
    // 3. æ¯ä¸ªçº¿ç¨‹æœ‰è‡ªå·±ç‹¬ç«‹çš„æ¥æ”¶ç¼“å†²åŒº
    struct mmsghdr msgs[BATCH_SIZE];
    struct iovec iovecs[BATCH_SIZE];
    char buffers[BATCH_SIZE][MTU_SIZE];
    struct sockaddr_in client_addrs[BATCH_SIZE];

    memset(msgs, 0, sizeof(msgs));
    for (int i = 0; i < BATCH_SIZE; i++) {
        iovecs[i].iov_base = buffers[i];
        iovecs[i].iov_len = MTU_SIZE;
        msgs[i].msg_hdr.msg_iov = &iovecs[i];
        msgs[i].msg_hdr.msg_iovlen = 1;
        msgs[i].msg_hdr.msg_name = &client_addrs[i];
        msgs[i].msg_hdr.msg_namelen = sizeof(struct sockaddr_in);
    }

    // 4. ç½‘ç»œå¾ªç¯ (ä¸åŸç‰ˆé€»è¾‘å‡ ä¹ç›¸åŒ)
    while (1) {
        int retval = recvmmsg(sockfd, msgs, BATCH_SIZE, 0, NULL);
        if (retval < 0) {
            if (errno == EINTR) continue;
            perror("recvmmsg error");
            break;
        }

        for (int i = 0; i < retval; i++) {
            if (msgs[i].msg_len >= sizeof(struct gvm_header)) {
                struct gvm_header *hdr = (struct gvm_header *)buffers[i];
                if (hdr->magic == GVM_MAGIC) {
                    handle_kvm_request(sockfd, &client_addrs[i], hdr, buffers[i] + sizeof(struct gvm_header));
                }
            }
            msgs[i].msg_hdr.msg_namelen = sizeof(struct sockaddr_in);
        }
    }
    
    close(sockfd);
    return NULL;
}
```

**æ–‡ä»¶**: `slave_daemon/cpu_executor.c`

```c
#define _GNU_SOURCE // ä¸ºäº† sched_setaffinity
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <pthread.h>
#include <unistd.h>
#include <sched.h> // åŒ…å« CPU äº²å’Œæ€§è®¾ç½®çš„å¤´æ–‡ä»¶
#include "../common_include/giantvm_protocol.h"

// å£°æ˜å¤–éƒ¨å‡½æ•°ï¼Œå®ƒå°†åœ¨å¦ä¸€ä¸ªæ–‡ä»¶ä¸­å®ç°å¹¶ä½œä¸ºçº¿ç¨‹çš„å…¥å£
extern void* network_thread_worker(void* arg);

// handle_kvm_request å‡½æ•°ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒå°†è¢« network_thread_worker è°ƒç”¨
void handle_kvm_request(int sockfd, struct sockaddr_in *client_addr, struct gvm_header *hdr, void *data) {
    switch (hdr->msg_type) {
        case MSG_MEM_READ: {
            struct gvm_header ack_hdr;
            char send_buf[MTU_SIZE];
            char payload[32] = "DATA_OK"; 
            ack_hdr.magic = GVM_MAGIC;
            ack_hdr.msg_type = MSG_MEM_ACK;
            ack_hdr.slave_id = hdr->slave_id;
            ack_hdr.req_id = hdr->req_id;
            ack_hdr.frag_seq = 0;
            ack_hdr.is_frag = 0;
            memcpy(send_buf, &ack_hdr, sizeof(ack_hdr));
            memcpy(send_buf + sizeof(ack_hdr), payload, sizeof(payload));
            int total_len = sizeof(ack_hdr) + sizeof(payload);
            sendto(sockfd, send_buf, total_len, 0, (struct sockaddr *)client_addr, sizeof(*client_addr));
            break;
        }
        case MSG_MEM_WRITE:
            break;
    }
}


int main() {
    // 1. è·å– CPU æ ¸å¿ƒæ•°
    long num_cores = sysconf(_SC_NPROCESSORS_ONLN);
    if (num_cores <= 0) {
        num_cores = 1; // å¤‡ç”¨å€¼
    }
    printf("[*] GiantVM Slave Daemon (Multi-Threaded SO_REUSEPORT)\n");
    printf("[*] Detected %ld CPU cores. Spawning worker threads...\n", num_cores);

    // 2. åˆ›å»ºçº¿ç¨‹å¥æŸ„æ•°ç»„
    pthread_t *threads = malloc(sizeof(pthread_t) * num_cores);
    if (!threads) {
        perror("Failed to allocate thread array");
        return 1;
    }

    // 3. å¾ªç¯åˆ›å»ºçº¿ç¨‹
    for (long i = 0; i < num_cores; i++) {
        // æˆ‘ä»¬å°†æ ¸å¿ƒ ID (i) ä½œä¸ºå‚æ•°ä¼ é€’ç»™çº¿ç¨‹
        // æ³¨æ„ï¼šç›´æ¥ä¼ é€’ i çš„åœ°å€æ˜¯é”™è¯¯çš„ï¼Œå› ä¸ºå¾ªç¯ä¼šæ”¹å˜ i çš„å€¼
        // æ­£ç¡®çš„åšæ³•æ˜¯ä¼ é€’ä¸€ä¸ª long ç±»å‹çš„æŒ‡é’ˆ
        long* core_id = malloc(sizeof(long));
        if (!core_id) {
            perror("Failed to allocate core_id");
            continue;
        }
        *core_id = i;
        
        if (pthread_create(&threads[i], NULL, network_thread_worker, core_id) != 0) {
            perror("Failed to create thread");
        }
    }

    // 4. ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ (å®é™…æœåŠ¡å™¨ä¸­è¿™é‡Œä¼šæ˜¯ä¸ªæ­»å¾ªç¯)
    for (long i = 0; i < num_cores; i++) {
        pthread_join(threads[i], NULL);
    }
    
    free(threads);
    return 0;
}
```

**æ–‡ä»¶**: `slave_daemon/Makefile`

```makefile
CC = gcc
# [ä¿®æ”¹] æ·»åŠ  -pthread
CFLAGS = -Wall -O3 -I../common_include -pthread 
TARGET = giantvm_slave
SRCS = cpu_executor.c net_uring.c # æ–‡ä»¶åä¿æŒä¸å˜ä¹Ÿå¯ä»¥

all: $(TARGET)

$(TARGET): $(SRCS)
	$(CC) $(CFLAGS) -o $@ $^

clean:
	rm -f $(TARGET)
```

---

## Step 7: æ§åˆ¶é¢å·¥å…· (Control Tool)

**æ–‡ä»¶**: `ctl_tool/gateway_list.txt` (ç¤ºä¾‹é…ç½®)

```text
# ID IP PORT
0 192.168.1.10 9000
1 192.168.1.11 9000
2 192.168.1.12 9000
```

**æ–‡ä»¶**: `ctl_tool/Makefile`

```makefile
CC = gcc
CFLAGS = -Wall -O2 -I../common_include
TARGET = gvm_ctl

all: $(TARGET)

$(TARGET): main.c
	$(CC) $(CFLAGS) -o $@ $<

clean:
	rm -f $(TARGET)
```

**æ–‡ä»¶**: `ctl_tool/main.c`

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <fcntl.h>
#include <unistd.h>
#include <sys/ioctl.h>
#include <arpa/inet.h>
#include <errno.h>

#include "giantvm_ioctl.h"

#define DEVICE_PATH "/dev/giantvm"
#define CONFIG_FILE "gateway_list.txt"

void die(const char *msg) {
    perror(msg);
    exit(EXIT_FAILURE);
}

int main(int argc, char *argv[]) {
    int fd;
    FILE *fp;
    char line[256];
    struct gvm_ioctl_gateway req;
    int count = 0;

    printf("[*] GiantVM Control Injector V16\n");

    // 1. Open Device
    fd = open(DEVICE_PATH, O_RDWR);
    if (fd < 0) die("[-] Failed to open /dev/giantvm");

    // 2. Open Config
    fp = fopen(CONFIG_FILE, "r");
    if (!fp) die("[-] Failed to open gateway_list.txt");

    // 3. Parse & Inject (Strict Logic: fscanf)
    while (fgets(line, sizeof(line), fp)) {
        // Skip comments and empty lines
        if (line[0] == '#' || line[0] == '\n' || line[0] == '\r') continue;

        char ip_str[32];
        int id, port;

        // Line format: ID IP PORT
        if (sscanf(line, "%d %31s %d", &id, ip_str, &port) != 3) {
            fprintf(stderr, "[!] Malformed line: %s", line);
            continue;
        }

        memset(&req, 0, sizeof(req));
        req.gw_id = (uint32_t)id;
        req.port = htons((uint16_t)port); // Network Byte Order
        
        if (inet_pton(AF_INET, ip_str, &req.ip) != 1) {
            fprintf(stderr, "[!] Invalid IP: %s\n", ip_str);
            continue;
        }

        // 4. IOCTL Call
        if (ioctl(fd, IOCTL_SET_GATEWAY, &req) < 0) {
            fprintf(stderr, "[-] IOCTL failed for GW %d: %s\n", id, strerror(errno));
        } else {
            printf("[+] Injected GW[%d] -> %s:%d\n", id, ip_str, port);
            count++;
        }
    }

    fclose(fp);
    close(fd);
    printf("[*] Done. Injected %d gateways.\n", count);
    return 0;
}
```

---

## Step 8: QEMU 5.2.0 é€‚é… (Frontend)

æ­¤éƒ¨åˆ†å°† GiantVM æ³¨å†Œä¸º QEMU åŠ é€Ÿå™¨ï¼Œå¹¶æ¥ç®¡ CPU è°ƒåº¦å¾ªç¯ã€‚

**æ–‡ä»¶**: `qemu_patch/accel/giantvm/giantvm-all.c`

```c
/*
 * GiantVM Accelerator Support for QEMU 5.2.0
 */

#include "qemu/osdep.h"
#include "qemu/module.h"
#include "sysemu/accel.h"
#include "sysemu/sysemu.h"
#include "hw/boards.h"
#include "qemu/option.h"
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <fcntl.h>
#include <sys/socket.h>
#include <sys/un.h>

// [æ–°å¢] å¼•å…¥æˆ‘ä»¬è‡ªå®šä¹‰çš„åè®®å’Œ UFFD æ¥å£
#include "giantvm_protocol.h" // å‡è®¾é€šè¿‡ CFLAGS åŒ…å«è·¯å¾„
extern void giantvm_uffd_init(int master_sock, void *ram_ptr, size_t ram_size);
extern void giantvm_setup_memory_region(MemoryRegion *mr, uint64_t size, int fd);

#define TYPE_GIANTVM_ACCEL "giantvm-accel"
#define GIANTVM_ACCEL(obj) \
    OBJECT_CHECK(GiantVMAccelState, (obj), TYPE_GIANTVM_ACCEL)

typedef enum {
    GVM_MODE_KERNEL,
    GVM_MODE_USER,
} GiantVMMode;

typedef struct GiantVMAccelState {
    AccelState parent_obj;
    // Mode A (Kernel)
    int dev_fd;
    // Mode B (User)
    int master_sock;
    // Common
    void *global_shared_mem;
    GiantVMMode mode;
} GiantVMAccelState;

static int giantvm_init_machine_kernel(GiantVMAccelState *s) {
    fprintf(stderr, "[GiantVM-QEMU] KERNEL MODE: Connecting to /dev/giantvm...\n");
    s->dev_fd = open("/dev/giantvm", O_RDWR);
    if (s->dev_fd < 0) {
        perror("[GiantVM] Failed to open /dev/giantvm");
        return -errno;
    }
    
    // åœ¨ Kernel Mode ä¸‹ï¼Œå†…å­˜ç›´æ¥ç”±å†…æ ¸æ¨¡å—é€šè¿‡ mmap æä¾›
    // æˆ‘ä»¬å°†åœ¨ memory.c çš„é€‚é…ä»£ç ä¸­å¤„ç†
    
    fprintf(stderr, "[GiantVM] Kernel connection established. FD=%d\n", s->dev_fd);
    return 0;
}

static int giantvm_init_machine_user(GiantVMAccelState *s, MachineState *ms) {
    fprintf(stderr, "[GiantVM-QEMU] USER MODE: Connecting to Master Process...\n");

    // 1. è¿æ¥åˆ° Master çš„ Unix Socket
    s->master_sock = socket(AF_UNIX, SOCK_STREAM, 0);
    if (s->master_sock < 0) {
        perror("[GiantVM] Failed to create unix socket");
        return -errno;
    }
    struct sockaddr_un addr = { .sun_family = AF_UNIX };
    strncpy(addr.sun_path, GVM_USER_SOCK_PATH, sizeof(addr.sun_path) - 1);
    
    if (connect(s->master_sock, (struct sockaddr*)&addr, sizeof(addr)) < 0) {
        perror("[GiantVM] Failed to connect to master process");
        close(s->master_sock);
        return -errno;
    }
    
    // 2. æ‰“å¼€å¹¶æ˜ å°„ç”± Master åˆ›å»ºçš„å…±äº«å†…å­˜
    int shm_fd = shm_open(GVM_USER_SHM_PATH, O_RDWR, 0666);
    if (shm_fd < 0) {
        perror("[GiantVM] Failed to open shared memory file");
        close(s->master_sock);
        return -errno;
    }
    
    // 3. å°†å…±äº«å†…å­˜æ³¨å†Œä¸º QEMU çš„ä¸» RAM
    giantvm_setup_memory_region(ms->ram, ms->ram_size, shm_fd);
    close(shm_fd);
    
    // 4. åˆå§‹åŒ– Userfaultfd æ¥æ•è·ç¼ºé¡µ
    giantvm_uffd_init(s->master_sock, ms->ram->ram_ptr, ms->ram_size);

    fprintf(stderr, "[GiantVM] User mode connection established. Sock=%d\n", s->master_sock);
    return 0;
}

static int giantvm_init_machine(MachineState *ms) {
    GiantVMAccelState *s = GIANTVM_ACCEL(ms->accelerator);
    if (s->mode == GVM_MODE_KERNEL) {
        return giantvm_init_machine_kernel(s);
    } else {
        return giantvm_init_machine_user(s, ms);
    }
}

// [æ–°å¢] å¤„ç† QEMU å‘½ä»¤è¡Œå‚æ•°
static void giantvm_accel_init(Object *obj) {
    GiantVMAccelState *s = GIANTVM_ACCEL(obj);
    
    // é»˜è®¤æ˜¯ Kernel Mode
    s->mode = GVM_MODE_KERNEL; 

    // æ·»åŠ  "mode" å±æ€§
    object_property_add_enum(obj, "mode", "GiantVMMode", &GiantVMMode_lookup,
                               (int64_t *)&s->mode, &error_abort);
}

static void giantvm_accel_class_init(ObjectClass *oc, void *data) {
    AccelClass *ac = ACCEL_CLASS(oc);
    ac->name = "GiantVM-X";
    ac->init_machine = giantvm_init_machine;
    ac->allowed = &error_abort;
}

static const TypeInfo giantvm_accel_type = {
    .name = TYPE_GIANTVM_ACCEL,
    .parent = TYPE_ACCEL,
    .instance_size = sizeof(GiantVMAccelState),
    .class_init = giantvm_accel_class_init,
    .instance_init = giantvm_accel_init, // [æ–°å¢]
};

// [æ–°å¢] å®šä¹‰æšä¸¾ç±»å‹ï¼Œç”¨äºå‘½ä»¤è¡Œè§£æ
static const char *GiantVMMode_lookup[] = {
    [GVM_MODE_KERNEL] = "kernel",
    [GVM_MODE_USER]   = "user",
    NULL
};

static void giantvm_type_init(void) {
    type_register_static(&giantvm_accel_type);
}

type_init(giantvm_type_init);

// [ä¿®æ”¹] å‘½ä»¤è¡Œå¯åŠ¨ç¤ºä¾‹:
// qemu-system-x86_64 -accel giantvm,mode=user -m 4G ...
```

**æ–‡ä»¶**: `qemu_patch/accel/giantvm/giantvm-cpu.c`

```c
#include "qemu/osdep.h"
#include "cpu.h"
#include "sysemu/cpus.h"
#include "qemu/guest-random.h"

/* 
 * CRITICAL IRON LAW: 
 * CPU Execution Loop Implementation 
 */

// Scheduler Policy Mockup
struct giantvm_policy_ops {
    int (*schedule_policy)(int cpu_index);
};

// Return 0 for Local (KVM), 1 for Remote (RPC)
static int remote_rpc_policy(int cpu_index) {
    // Logic: In 100k scale, most CPUs are remote.
    // Here we mock a static policy for demonstration.
    // e.g., CPU 0 is local, others are remote.
    if (cpu_index == 0) return 0;
    return 1;
}

static struct giantvm_policy_ops ops = {
    .schedule_policy = remote_rpc_policy
};

/*
 * The GiantVM vCPU Execution Loop
 */
static void *giantvm_cpu_thread_fn(void *arg) {
    CPUState *cpu = arg;

    rcu_register_thread();
    cpu->halted = 0;

    while (1) {
        // 1. Policy Check: Local or Remote?
        int policy = ops.schedule_policy(cpu->cpu_index);

        if (policy == 1) {
            // Remote CPU: Wait for RPC completion (Simulated)
            // In real logic, this blocks on a condition var triggered by incoming RPC
            g_usleep(1000); 
            
            // Check exit conditions
            if (cpu->unplug || cpu->stop) break;
            continue;
        }

        // 2. Local Execution Block
        if (cpu_can_run(cpu)) {
            qemu_mutex_lock_iothread();
            // giantvm_cpu_exec(cpu); // Calls KVM_RUN underneath
            // For now, we simulate execution time
            qemu_mutex_unlock_iothread();
        }

        // 3. Handle Exit / IO
        qemu_wait_io_event(cpu);
        
        if (cpu->unplug || cpu->stop) {
            break;
        }
    }

    rcu_unregister_thread();
    return NULL;
}

void giantvm_start_vcpu_thread(CPUState *cpu) {
    char thread_name[VCPU_THREAD_NAME_SIZE];
    
    cpu->thread = g_malloc0(sizeof(QemuThread));
    cpu->halt_cond = g_malloc0(sizeof(QemuCond));
    qemu_cond_init(cpu->halt_cond);
    
    snprintf(thread_name, VCPU_THREAD_NAME_SIZE, "CPU %d/GVM", cpu->cpu_index);
    qemu_thread_create(cpu->thread, thread_name, giantvm_cpu_thread_fn,
                       cpu, QEMU_THREAD_JOINABLE);
}
```

**æ–‡ä»¶**: `qemu_patch/hw/giantvm/giantvm_mem.c`

```c
#include "qemu/osdep.h"
#include "exec/memory.h"
#include "qemu/mmap-alloc.h"

/*
 * Memory Interception for Infinite Scale
 * Maps QEMU RAM directly to GiantVM Kernel Module (Mode A)
 * or a Shared Memory File (Mode B)
 */

void giantvm_setup_memory_region(MemoryRegion *mr, uint64_t size, int fd) {
    void *ptr;

    // 1. mmap from the provided file descriptor
    // Mode A: fd is from /dev/giantvm
    // Mode B: fd is from /dev/shm/giantvm_ram
    ptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
    
    if (ptr == MAP_FAILED) {
        fprintf(stderr, "GiantVM: Failed to mmap guest memory from fd=%d. Error: %s\n", 
                fd, strerror(errno));
        exit(1);
    }

    // 2. Register with QEMU Memory System
    memory_region_init_ram_ptr(mr, NULL, "giantvm-ram", size, ptr);
    
    fprintf(stderr, "GiantVM: Mapped %lu bytes of guest memory from fd=%d.\n", size, fd);
}
```

**æ–‡ä»¶**: `qemu_patch/accel/giantvm/giantvm-uffd.c`

```c
#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <pthread.h>
#include <poll.h>
#include <errno.h>
#include <sys/syscall.h>
#include <sys/ioctl.h>
#include <linux/userfaultfd.h>

#include "qemu/osdep.h"
#include "giantvm_protocol.h"

// [æ–°å¢] å®šä¹‰ä»»åŠ¡å’Œä»»åŠ¡é˜Ÿåˆ—
// ---------------------------------------------------------
#define MAX_PENDING_FAULTS 1024 // ä»»åŠ¡é˜Ÿåˆ—çš„å®¹é‡
#define NUM_WORKER_THREADS 8    // å·¥ä½œçº¿ç¨‹æ•°é‡

// ä»£è¡¨ä¸€ä¸ªéœ€è¦å¤„ç†çš„ç¼ºé¡µä»»åŠ¡
typedef struct {
    uint64_t gpa;
    uint64_t len;
} uffd_task_t;

// çº¿ç¨‹å®‰å…¨çš„ç¯å½¢ç¼“å†²åŒº (Ring Buffer)
typedef struct {
    uffd_task_t tasks[MAX_PENDING_FAULTS];
    int head;
    int tail;
    pthread_mutex_t lock;
    pthread_cond_t not_empty; // æ¡ä»¶å˜é‡: é˜Ÿåˆ—éç©º
    pthread_cond_t not_full;  // æ¡ä»¶å˜é‡: é˜Ÿåˆ—éæ»¡
} task_queue_t;

// [æ–°å¢] å…¨å±€å˜é‡
// ---------------------------------------------------------
static int g_uffd = -1;
static int g_master_sock = -1;
static task_queue_t g_task_queue;


// [æ–°å¢] ä»»åŠ¡é˜Ÿåˆ—çš„åˆå§‹åŒ–å’Œæ“ä½œ
// ---------------------------------------------------------
static void queue_init(task_queue_t *q) {
    q->head = 0;
    q->tail = 0;
    pthread_mutex_init(&q->lock, NULL);
    pthread_cond_init(&q->not_empty, NULL);
    pthread_cond_init(&q->not_full, NULL);
}

static void queue_push(task_queue_t *q, uffd_task_t task) {
    pthread_mutex_lock(&q->lock);
    // å¦‚æœé˜Ÿåˆ—å·²æ»¡ï¼Œç­‰å¾… Worker å–èµ°ä»»åŠ¡åå†æ”¾å…¥
    while ((q->tail + 1) % MAX_PENDING_FAULTS == q->head) {
        pthread_cond_wait(&q->not_full, &q->lock);
    }
    q->tasks[q->tail] = task;
    q->tail = (q->tail + 1) % MAX_PENDING_FAULTS;
    pthread_cond_signal(&q->not_empty); // é€šçŸ¥ç­‰å¾…çš„ Worker
    pthread_mutex_unlock(&q->lock);
}

static uffd_task_t queue_pop(task_queue_t *q) {
    pthread_mutex_lock(&q->lock);
    // å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œç­‰å¾… Distributor æ”¾å…¥ä»»åŠ¡
    while (q->head == q->tail) {
        pthread_cond_wait(&q->not_empty, &q->lock);
    }
    uffd_task_t task = q->tasks[q->head];
    q->head = (q->head + 1) % MAX_PENDING_FAULTS;
    pthread_cond_signal(&q->not_full); // é€šçŸ¥ç­‰å¾…çš„ Distributor
    pthread_mutex_unlock(&q->lock);
    return task;
}


// [ä¿®æ”¹] Worker çº¿ç¨‹ (æ¶ˆè´¹è€…)
// ---------------------------------------------------------
static void *worker_thread(void *arg) {
    long thread_id = (long)arg;
    printf("[Worker %ld] Started.\n", thread_id);

    while (1) {
        // 1. ä»é˜Ÿåˆ—ä¸­å®‰å…¨åœ°å–å‡ºä¸€ä¸ªä»»åŠ¡ (å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œæ­¤å‡½æ•°ä¼šé˜»å¡)
        uffd_task_t task = queue_pop(&g_task_queue);

        // 2. æ‰§è¡Œè€—æ—¶çš„ IPC æ“ä½œ
        struct gvm_ipc_fault_req req = { .gpa = task.gpa, .len = task.len };
        if (write(g_master_sock, &req, sizeof(req)) != sizeof(req)) {
            fprintf(stderr, "[Worker %ld] Failed to send fault request\n", thread_id);
            continue;
        }

        struct gvm_ipc_fault_ack ack;
        if (read(g_master_sock, &ack, sizeof(ack)) != sizeof(ack)) {
            fprintf(stderr, "[Worker %ld] Failed to receive ACK\n", thread_id);
            continue;
        }

        // 3. å”¤é†’é¡µé¢
        struct uffdio_wake wake = { .range = { .start = task.gpa, .len = task.len } };
        if (ioctl(g_uffd, UFFDIO_WAKE, &wake) < 0 && errno != EEXIST) {
            perror("[Worker] UFFDIO_WAKE failed");
        }
    }
    return NULL;
}


// [ä¿®æ”¹] Distributor çº¿ç¨‹ (ç”Ÿäº§è€…)
// ---------------------------------------------------------
static void *distributor_thread(void *arg) {
    struct pollfd pollfd = { .fd = g_uffd, .events = POLLIN };
    printf("[Distributor] Started.\n");

    while (poll(&pollfd, 1, -1) > 0) {
        struct uffd_msg msg;
        if (read(g_uffd, &msg, sizeof(msg)) != sizeof(msg)) continue;

        if (msg.event == UFFD_EVENT_PAGEFAULT) {
            // æ”¶åˆ°ç¼ºé¡µäº‹ä»¶ï¼Œå¿«é€Ÿæ‰“åŒ…æˆä»»åŠ¡ï¼Œæ”¾å…¥é˜Ÿåˆ—
            uffd_task_t task = {
                .gpa = msg.arg.pagefault.address,
                .len = 4096,
            };
            queue_push(&g_task_queue, task);
        }
    }
    fprintf(stderr, "[Distributor] Exited poll loop, something is wrong.\n");
    return NULL;
}


// [ä¿®æ”¹] åˆå§‹åŒ–å‡½æ•°
// ---------------------------------------------------------
void giantvm_uffd_init(int master_sock, void *ram_ptr, size_t ram_size) {
    pthread_t thread;

    g_master_sock = master_sock;
    queue_init(&g_task_queue); // åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—

    // 1. åˆ›å»º userfaultfd (é€»è¾‘ä¸å˜)
    g_uffd = syscall(__NR_userfaultfd, O_CLOEXEC | O_NONBLOCK);
    if (g_uffd < 0) die("userfaultfd syscall");

    struct uffdio_api api = { .api = UFFD_API, .features = 0 };
    if (ioctl(g_uffd, UFFDIO_API, &api) < 0) die("UFFDIO_API");

    struct uffdio_register reg = {
        .range = { .start = (uint64_t)ram_ptr, .len = ram_size },
        .mode = UFFDIO_REGISTER_MODE_MISSING,
    };
    if (ioctl(g_uffd, UFFDIO_REGISTER, &reg) < 0) die("UFFDIO_REGISTER");

    // 2. åˆ›å»ºå¹¶å¯åŠ¨ N ä¸ª Worker çº¿ç¨‹
    for (long i = 0; i < NUM_WORKER_THREADS; i++) {
        pthread_create(&thread, NULL, worker_thread, (void*)i);
    }
    
    // 3. åˆ›å»ºå¹¶å¯åŠ¨ 1 ä¸ª Distributor çº¿ç¨‹
    pthread_create(&thread, NULL, distributor_thread, NULL);
    
    fprintf(stderr, "[GiantVM] Multi-threaded UFFD handler initialized (%d workers).\n", NUM_WORKER_THREADS);
}
```

---

## Step 9: ä¼˜åŒ–çš„ç½‘å…³ (Gateway)

æ­¤æ¨¡å—è¿è¡Œåœ¨ç”¨æˆ·æ€ï¼Œæ˜¯è¿æ¥ QEMU å’Œç‰©ç†ç½‘ç»œçš„æ¢çº½ã€‚ä¸ºäº†æ”¯æŒ 100,000+ èŠ‚ç‚¹ï¼Œå¿…é¡»ä½¿ç”¨**æŒ‰éœ€åˆ†é…ï¼ˆLazy Allocationï¼‰**ç­–ç•¥ï¼Œä¸¥ç¦ä¸€æ¬¡æ€§åˆ†é…æ‰€æœ‰èŠ‚ç‚¹çš„ç¼“å†²åŒºï¼ˆé‚£ä¼šç¬é—´æ¶ˆè€—æ•°ç™¾ MB å†…å­˜ï¼‰ã€‚

**æ–‡ä»¶**: `gateway_service/aggregator.h` (æ¥å£å®šä¹‰)

```c
#ifndef AGGREGATOR_H
#define AGGREGATOR_H

#include <stdint.h>
#include <stddef.h>
#include "../common_include/giantvm_config.h"

// èšåˆç¼“å†²åŒºç»“æ„ (MTU å¯¹é½)
typedef struct {
    uint32_t current_len;
    uint8_t  raw_data[MTU_SIZE];
} slave_buffer_t;

/* åˆå§‹åŒ–èšåˆå™¨ (äºŒçº§æŒ‡é’ˆè¡¨) */
int init_aggregator(void);

/* æ¨é€æ•°æ®ï¼Œè‡ªåŠ¨å¤„ç†æŒ‰éœ€å†…å­˜åˆ†é…ä¸èšåˆå‘é€ */
int push_to_aggregator(uint32_t slave_id, void *data, int len);

/* å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ´»è·ƒç¼“å†²åŒº */
void flush_all_buffers(void);

#endif // AGGREGATOR_H
```

**æ–‡ä»¶**: `gateway_service/aggregator.c`

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <errno.h>
#include <arpa/inet.h>
#include <fcntl.h>
#include <pthread.h> // å¼•å…¥çº¿ç¨‹æ”¯æŒ
#include "aggregator.h"

// ---------------------------------------------------------
// 1. Structure Definition
// ---------------------------------------------------------
static slave_buffer_t **buffers = NULL;
static int gw_sockfd = -1;
static struct sockaddr_in slave_addr_template;

// ---------------------------------------------------------
// 2. Per-Slave Mutex
// ---------------------------------------------------------
static pthread_mutex_t *slave_locks = NULL;

// ---------------------------------------------------------
// 3. Real Non-Blocking Send
// ---------------------------------------------------------
static int raw_send_to_slave(uint32_t slave_id, void *data, int len) {
    if (gw_sockfd < 0) return -1;

    // ç®€å• IP æ˜ å°„è§„åˆ™: 10.0.x.x
    // å®é™…ç”Ÿäº§ç¯å¢ƒåº”æŸ¥è¡¨ slave_ip_table[slave_id]
    // è¿™é‡Œä¸ºäº†æ¼”ç¤ºç›´æ¥è®¡ç®— IP
    uint32_t ip_suffix = slave_id + 1;
    slave_addr_template.sin_addr.s_addr = htonl(0x0A000000 + ip_suffix);

    // [Safety Fix] MSG_DONTWAIT prevents blocking the gateway thread
    int ret = sendto(gw_sockfd, data, len, MSG_DONTWAIT,
                     (struct sockaddr*)&slave_addr_template,
                     sizeof(slave_addr_template));

    if (ret < 0) {
        if (errno == EAGAIN || errno == EWOULDBLOCK) {
            // Buffer Full. Drop packet or buffer it.
            // For V16 simple implementation, we return error (Drop)
            // Log rate limited in production
            return -EAGAIN;
        }
        perror("sendto");
    }
    return ret;
}

// ---------------------------------------------------------
// 4. Init
// ---------------------------------------------------------
int init_aggregator(void) {
    if (buffers) return 0;

    buffers = (slave_buffer_t **)calloc(GVM_MAX_SLAVES, sizeof(void*));
    if (!buffers) {
        perror("calloc(buffers)");
        return -ENOMEM;
    }

    // [å®‰å…¨å¢å¼º] åˆå§‹åŒ– slave é”æ•°ç»„
    slave_locks = (pthread_mutex_t *)malloc(sizeof(pthread_mutex_t) * GVM_MAX_SLAVES);
    if (!slave_locks) {
        perror("malloc(slave_locks)");
        free(buffers);
        buffers = NULL;
        return -ENOMEM;
    }
    for (uint32_t i = 0; i < GVM_MAX_SLAVES; i++) {
        if (pthread_mutex_init(&slave_locks[i], NULL) != 0) {
             perror("pthread_mutex_init");
            // æ¸…ç†ä¹‹å‰åˆ†é…çš„é”
            for (uint32_t j = 0; j < i; j++) {
                pthread_mutex_destroy(&slave_locks[j]);
            }
            free(slave_locks);
            free(buffers);
            buffers = NULL;
            slave_locks = NULL;
            return -errno;
        }
    }

    // [Updated] Initialize Socket
    gw_sockfd = socket(AF_INET, SOCK_DGRAM, 0);
    if (gw_sockfd < 0) {
        perror("socket");
        return -errno;
    }

    // Set Non-Blocking just in case
    int flags = fcntl(gw_sockfd, F_GETFL, 0);
    fcntl(gw_sockfd, F_SETFL, flags | O_NONBLOCK);

    // Prepare template
    memset(&slave_addr_template, 0, sizeof(slave_addr_template));
    slave_addr_template.sin_family = AF_INET;
    slave_addr_template.sin_port = htons(9000); // Standard Slave Port

    printf("[Aggregator] Initialized for %lu nodes with UDP Socket.\n", GVM_MAX_SLAVES);
    return 0;
}

// ---------------------------------------------------------
// 5. Flush & Push (Same Logic, using real send)
// ---------------------------------------------------------
static void flush_buffer(uint32_t id) {
    if (!buffers || !buffers[id]) return;

    slave_buffer_t *buf = buffers[id];
    if (buf->current_len > 0) {
        raw_send_to_slave(id, buf->raw_data, buf->current_len);
        buf->current_len = 0;
    }
}

int push_to_aggregator(uint32_t slave_id, void *data, int len) {
    if (slave_id >= GVM_MAX_SLAVES) return -EINVAL;
    if (len > MTU_SIZE) return -E2BIG;

    pthread_mutex_lock(&slave_locks[slave_id]);
    
    if (!buffers[slave_id]) {
        buffers[slave_id] = (slave_buffer_t *)malloc(sizeof(slave_buffer_t));
        if (!buffers[slave_id]) {
            pthread_mutex_unlock(&slave_locks[slave_id]);
            return -ENOMEM;
        }
        buffers[slave_id]->current_len = 0;
    }

    slave_buffer_t *buf = buffers[slave_id];

    if (buf->current_len + len > MTU_SIZE) {
        flush_buffer(slave_id);
    }

    memcpy(buf->raw_data + buf->current_len, data, len);
    buf->current_len += len;

    pthread_mutex_unlock(&slave_locks[slave_id]);
    return 0;
}

void flush_all_buffers(void) {
    if (!buffers) return;
    for (uint32_t i = 0; i < GVM_MAX_SLAVES; i++) {
        pthread_mutex_lock(&slave_locks[i]); // ç¡®ä¿å®‰å…¨
        if (buffers[i] && buffers[i]->current_len > 0) {
            flush_buffer(i);
        }
        pthread_mutex_unlock(&slave_locks[i]);
    }
}

// ---------------------------------------------------------
// 6. Exit (Cleanup) - IMPORTANT
// ---------------------------------------------------------
void cleanup_aggregator(void) {
    if (slave_locks) {
        for (uint32_t i = 0; i < GVM_MAX_SLAVES; i++) {
            pthread_mutex_destroy(&slave_locks[i]);
        }
        free(slave_locks);
        slave_locks = NULL;
    }
    if (buffers) {
        for (uint32_t i = 0; i < GVM_MAX_SLAVES; i++) {
            free(buffers[i]);
        }
        free(buffers);
        buffers = NULL;
    }
    if (gw_sockfd != -1) {
        close(gw_sockfd);
        gw_sockfd = -1;
    }
}
```

---

## Step 10: Guest å·¥å…· (Guest Tools)

æ­¤ä»£ç åœ¨ Windows è™šæ‹Ÿæœºå†…éƒ¨ç¼–è¯‘è¿è¡Œï¼ˆéœ€è¦ MSVC æˆ– MinGWï¼‰ï¼Œç”¨äºé…åˆ GiantVM çš„å†…å­˜æ‹¦æˆªæœºåˆ¶ã€‚é€šè¿‡æ¨¡æ‹Ÿå¤§é¡µåˆ†é…å’Œè®¿é—®æ¨¡å¼ï¼Œå‘åº•å±‚ Hypervisor æš—ç¤ºè™šæ‹Ÿ NUMA æ‹“æ‰‘ã€‚

**æ–‡ä»¶**: `guest_tools/win_memory_hint.cpp`

```cpp
#include <windows.h>
#include <iostream>
#include <vector>

/*
 * GiantVM vNUMA Hint Tool for Frontier-X V16
 * Target: Windows Guest OS
 * Purpose: Pre-fault memory to trigger GiantVM Kernel Backend (MSG_MEM_READ)
 */

// Define generic structure if not available in older SDKs
typedef struct _GVM_NUMA_NODE {
    DWORD NodeNumber;
    DWORD64 AvailableMemory;
} GVM_NUMA_NODE;

void InjectFakeNUMATopology() {
    std::cout << "[*] GiantVM: Injecting vNUMA Hints..." << std::endl;
    
    // 1. Enable Large Pages Privilege (Required for performance)
    HANDLE hToken;
    TOKEN_PRIVILEGES tp;
    if (OpenProcessToken(GetCurrentProcess(), TOKEN_ADJUST_PRIVILEGES | TOKEN_QUERY, &hToken)) {
        LookupPrivilegeValue(NULL, SE_LOCK_MEMORY_NAME, &tp.Privileges[0].Luid);
        tp.PrivilegeCount = 1;
        tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED;
        AdjustTokenPrivileges(hToken, FALSE, &tp, 0, (PTOKEN_PRIVILEGES)NULL, 0);
        CloseHandle(hToken);
    }

    // 2. Allocate Large Page Memory (Simulate GiantVM Geometric Partition)
    // 2MB is the standard HugePage size on x86_64
    SIZE_T size = 1024 * 1024 * 2; 
    void* ptr = VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE | MEM_LARGE_PAGES, PAGE_READWRITE);
    
    if (ptr) {
        std::cout << "[+] 2MB HugePage Allocated at: 0x" << ptr << std::endl;
        
        // 3. Locking memory prevents swapping, keeping the mapping active in EPT
        if (VirtualLock(ptr, size)) {
            std::cout << "[+] Memory Locked (Pinned)." << std::endl;
        } else {
             std::cerr << "[-] VirtualLock failed. Error: " << GetLastError() << std::endl;
        }

        // 4. Access Pattern to Trigger Fault
        // This Write causes an EPT Violation -> KVM Exit -> GiantVM Handler
        volatile int* data = (volatile int*)ptr;
        try {
            *data = 0xGVMX; // Magic write
            std::cout << "[+] Memory touched successfully." << std::endl;
        } catch (...) {
            std::cerr << "[!] Exception during memory touch." << std::endl;
        }

    } else {
        std::cerr << "[-] Failed to alloc HugePages. Check 'Lock Pages in Memory' policy." << std::endl;
        std::cerr << "    Error Code: " << GetLastError() << std::endl;
        
        // Fallback to standard 4K pages
        ptr = VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE);
        if (ptr) std::cout << "[!] Fallback: Standard 4K pages allocated." << std::endl;
    }
}

int main() {
    std::cout << "GiantVM Frontier-X V16 Guest Tool" << std::endl;
    std::cout << "=================================" << std::endl;
    
    InjectFakeNUMATopology();
    
    std::cout << "[*] Optimization Complete. Sleeping to hold memory mapping..." << std::endl;
    
    // Keep process alive to maintain memory locks if OS policy requires it
    while (true) {
        Sleep(10000); 
    }
    
    return 0;
}
```

---

### å…¨å±€å®Œæˆç¡®è®¤

è‡³æ­¤ï¼ŒGiantVM "Frontier-X" V16 çš„æ‰€æœ‰ä»£ç æ¨¡å—ï¼ˆStep 0 åˆ° Step 10ï¼‰å‡å·²ç”Ÿæˆå®Œæ¯•ã€‚

1.  **å†…æ ¸æ€**: `kernel_backend.c` (æ­»é”é˜²æŠ¤, `vzalloc` å¤§è¡¨, `mmap` æ‹¦æˆª).
2.  **æ ¸å¿ƒé€»è¾‘**: `logic_core.c` (RUDP å¯é ä¼ è¾“, æ— çŠ¶æ€è·¯ç”±).
3.  **ç”¨æˆ·æ€**: `user_backend.c` (å…¼å®¹æ€§åç«¯), `gateway_service` (Lazy Alloc èšåˆ).
4.  **å‰ç«¯**: `qemu_patch` (AccelClass é›†æˆ).
5.  **ä»èŠ‚ç‚¹**: `slave_daemon` (Raw Syscall io_uring).
6.  **å·¥å…·**: `ctl_tool` (æ— ä¾èµ–æ³¨å…¥), `guest_tools` (Win32 API).

**å»ºè®®ç¼–è¯‘é¡ºåº**:
1.  `master_core` (Kernel Module)
2.  `ctl_tool`
3.  `gateway_service`
4.  `slave_daemon`
5.  åº”ç”¨ QEMU Patch å¹¶ç¼–è¯‘ QEMUã€‚
